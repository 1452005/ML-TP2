{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créer un nouveau notebook Python et taper le code suivant dans une nouvelle cellule :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(threshold=np.nan,suppress=True)\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Chargement des données et préparation : Dans un premier temps nous allons importer le jeu de données et analyser ses caractéristiques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## • Importer ce jeu de données avec la librairie pandas (c.f. read_csv)\n",
    "\n",
    "## • Transformer votre jeu de données issue de pandas qui sera de type Data Frame en numpy Array (c.f. values) et séparer ensuite les variables caractéristiques de la variable à prédire (status) en deux tableaux différents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv('./credit_scoring.csv', sep=';')\n",
    "data = data_df.values\n",
    "#  variables caractéristiques \n",
    "X = data[:,0:13]\n",
    "#  variable à prédire\n",
    "Y = data[:,13]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## • Analyser les propriétés de vos données : taille de l’échantillon (c.f. shape), nombre d’exemples positifs et négatifs (c.f. hist)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4375, 14)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a 4375 observations dans notre l’échantillon et 14 colonnes (c.à.d 13 variables caractéristiques + 1 variable à prédire)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x00000141102E6A58>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x00000141105B32B0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x00000141105DE940>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x0000014110606FD0>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x00000141106356A0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x00000141106356D8>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001411068F400>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x00000141106B4A90>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x00000141106E6160>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001411070E7F0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x0000014110736E80>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x0000014110768550>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x000001411078FBE0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x00000141107C32B0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x00000141107E8940>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x0000014110811FD0>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_df.hist(bins = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## • Pour éviter d’avoir un résultat biaisé du classifieur que nous allons construire, séparer les données en deux partie une dite d’apprentissage qui servira à l’apprentissage du classifieur et l’autre dite de test qui servira à son évaluation (c.f. train_test_split)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "on split notre dataset en deux parties ( un tier pour le test, et deux tiers pour training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Apprentissage et évaluation de modèles : Utiliser ensuite sur votre jeu de données les algorithmes d’apprentissage supervisé suivants :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## • Un arbre CART (random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L’accuracy d'un arbre CART: 71.26038781163435 %\n",
      "La precision d'un arbre CART: 79.81132075471699 %\n",
      "Le rappel d'un arbre CART: 80.80229226361033 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier(random_state=1)\n",
    "clf = clf.fit(X_train, Y_train)\n",
    "Y_pred = clf.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"L’accuracy d'un arbre CART:\", accuracy_score(Y_test, Y_pred)*100, \"%\")\n",
    "from sklearn.metrics import precision_score\n",
    "print(\"La precision d'un arbre CART:\", precision_score(Y_test, Y_pred)*100, \"%\")\n",
    "from sklearn.metrics import recall_score\n",
    "print(\"Le rappel d'un arbre CART:\", recall_score(Y_test, Y_pred)*100, \"%\")\n",
    "\n",
    "arbre = [accuracy_score(Y_test, Y_pred)*100, precision_score(Y_test, Y_pred)*100, recall_score(Y_test, Y_pred)*100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## • k-plus-proches-voisins avec k=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L’accuracy d'un arbre CART: 72.02216066481995 %\n",
      "La precision d'un arbre CART: 77.03952901597981 %\n",
      "Le rappel d'un arbre CART: 87.48806112702961 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf = KNeighborsClassifier(n_neighbors=5)\n",
    "clf = clf.fit(X_train, Y_train)\n",
    "Y_pred = clf.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"L’accuracy d'un arbre CART:\", accuracy_score(Y_test, Y_pred)*100, \"%\")\n",
    "from sklearn.metrics import precision_score\n",
    "print(\"La precision d'un arbre CART:\", precision_score(Y_test, Y_pred)*100, \"%\")\n",
    "from sklearn.metrics import recall_score\n",
    "print(\"Le rappel d'un arbre CART:\", recall_score(Y_test, Y_pred)*100, \"%\")\n",
    "\n",
    "knn = [accuracy_score(Y_test, Y_pred)*100, precision_score(Y_test, Y_pred)*100, recall_score(Y_test, Y_pred)*100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entre la presicion et le rappel, dans cette application de credit scoring, le presicion est le meilleur critère pour comparer les classifications. Car plus la précision est élevée, plus le faux négatif est faible, ce qui signifie que le montant des créances irrécouvrables (pertes financières) est faible pour la banque. En outre, la précision signifie la perte de client potentiel.\n",
    "\n",
    "En basant sur l'accuracy et le rappel des deux algorithmes, on peut voir que la classification d'arbre CART est préférable de détecter les bons clients et que la classification KNN est préférable de réduire le taux de fausses évaluations des mauvais emprunteurs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Normalisation des variables continues :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MinMaxScaler:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X)\n",
    "X_scaled = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_scaled, Y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L’accuracy d'un arbre CART: 71.26038781163435 %\n",
      "La precision d'un arbre CART: 79.86767485822305 %\n",
      "Le rappel d'un arbre CART: 80.70678127984718 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier(random_state=1)\n",
    "clf = clf.fit(X_train, Y_train)\n",
    "Y_pred = clf.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"L’accuracy d'un arbre CART:\", accuracy_score(Y_test, Y_pred)*100, \"%\")\n",
    "from sklearn.metrics import precision_score\n",
    "print(\"La precision d'un arbre CART:\", precision_score(Y_test, Y_pred)*100, \"%\")\n",
    "from sklearn.metrics import recall_score\n",
    "print(\"Le rappel d'un arbre CART:\", recall_score(Y_test, Y_pred)*100, \"%\")\n",
    "\n",
    "arbre_scaled = [accuracy_score(Y_test, Y_pred)*100, precision_score(Y_test, Y_pred)*100, recall_score(Y_test, Y_pred)*100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L’accuracy d'un arbre CART: 74.65373961218836 %\n",
      "La precision d'un arbre CART: 80.0 %\n",
      "Le rappel d'un arbre CART: 86.72397325692455 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf = KNeighborsClassifier(n_neighbors=5)\n",
    "clf = clf.fit(X_train, Y_train)\n",
    "Y_pred = clf.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"L’accuracy d'un arbre CART:\", accuracy_score(Y_test, Y_pred)*100, \"%\")\n",
    "from sklearn.metrics import precision_score\n",
    "print(\"La precision d'un arbre CART:\", precision_score(Y_test, Y_pred)*100, \"%\")\n",
    "from sklearn.metrics import recall_score\n",
    "print(\"Le rappel d'un arbre CART:\", recall_score(Y_test, Y_pred)*100, \"%\")\n",
    "\n",
    "knn_scaled = [accuracy_score(Y_test, Y_pred)*100, precision_score(Y_test, Y_pred)*100, recall_score(Y_test, Y_pred)*100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>KNN</th>\n",
       "      <th>KNN normalisé</th>\n",
       "      <th>arbre</th>\n",
       "      <th>arbre normalisé</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>72.022161</td>\n",
       "      <td>74.653740</td>\n",
       "      <td>71.260388</td>\n",
       "      <td>71.260388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Precision</td>\n",
       "      <td>77.039529</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>79.811321</td>\n",
       "      <td>79.867675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rappel</td>\n",
       "      <td>87.488061</td>\n",
       "      <td>86.723973</td>\n",
       "      <td>80.802292</td>\n",
       "      <td>80.706781</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    KNN  KNN normalisé      arbre  arbre normalisé\n",
       "0   Accuracy  72.022161      74.653740  71.260388        71.260388\n",
       "1  Precision  77.039529      80.000000  79.811321        79.867675\n",
       "2     Rappel  87.488061      86.723973  80.802292        80.706781"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d={'':['Accuracy','Precision','Rappel'], 'arbre':arbre,'KNN':knn,'arbre normalisé':arbre_scaled,'KNN normalisé':knn_scaled}\n",
    "df = pd.DataFrame(data=d)\n",
    "df.reindex_axis(sorted(df.columns), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# à conclure: chung ta làm table r KL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Création de nouvelles variables caractéristiques par combinaisons linéaires des variables initiales :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA()\n",
    "pca.fit(X_scaled)\n",
    "X_pca = pca.transform(X_scaled)\n",
    "X_pca = np.concatenate((X_scaled, X_pca), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_pca, Y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L’accuracy d'un arbre CART: 71.81440443213296 %\n",
      "La precision d'un arbre CART: 80.01876172607881 %\n",
      "Le rappel d'un arbre CART: 81.47086914995224 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier(random_state=1)\n",
    "clf = clf.fit(X_train, Y_train)\n",
    "Y_pred = clf.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"L’accuracy d'un arbre CART:\", accuracy_score(Y_test, Y_pred)*100, \"%\")\n",
    "from sklearn.metrics import precision_score\n",
    "print(\"La precision d'un arbre CART:\", precision_score(Y_test, Y_pred)*100, \"%\")\n",
    "from sklearn.metrics import recall_score\n",
    "print(\"Le rappel d'un arbre CART:\", recall_score(Y_test, Y_pred)*100, \"%\")\n",
    "\n",
    "arbre_pca = [accuracy_score(Y_test, Y_pred)*100, precision_score(Y_test, Y_pred)*100, recall_score(Y_test, Y_pred)*100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L’accuracy d'un arbre CART: 74.65373961218836 %\n",
      "La precision d'un arbre CART: 80.0 %\n",
      "Le rappel d'un arbre CART: 86.72397325692455 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf = KNeighborsClassifier(n_neighbors=5)\n",
    "clf = clf.fit(X_train, Y_train)\n",
    "Y_pred = clf.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"L’accuracy d'un arbre CART:\", accuracy_score(Y_test, Y_pred)*100, \"%\")\n",
    "from sklearn.metrics import precision_score\n",
    "print(\"La precision d'un arbre CART:\", precision_score(Y_test, Y_pred)*100, \"%\")\n",
    "from sklearn.metrics import recall_score\n",
    "print(\"Le rappel d'un arbre CART:\", recall_score(Y_test, Y_pred)*100, \"%\")\n",
    "\n",
    "knn_pca = [accuracy_score(Y_test, Y_pred)*100, precision_score(Y_test, Y_pred)*100, recall_score(Y_test, Y_pred)*100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>KNN</th>\n",
       "      <th>KNN normalisé</th>\n",
       "      <th>KNN pca</th>\n",
       "      <th>arbre</th>\n",
       "      <th>arbre normalisé</th>\n",
       "      <th>arbre pca</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>72.022161</td>\n",
       "      <td>74.653740</td>\n",
       "      <td>74.653740</td>\n",
       "      <td>71.260388</td>\n",
       "      <td>71.260388</td>\n",
       "      <td>71.814404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Precision</td>\n",
       "      <td>77.039529</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>79.811321</td>\n",
       "      <td>79.867675</td>\n",
       "      <td>80.018762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rappel</td>\n",
       "      <td>87.488061</td>\n",
       "      <td>86.723973</td>\n",
       "      <td>86.723973</td>\n",
       "      <td>80.802292</td>\n",
       "      <td>80.706781</td>\n",
       "      <td>81.470869</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    KNN  KNN normalisé    KNN pca      arbre  arbre normalisé  \\\n",
       "0   Accuracy  72.022161      74.653740  74.653740  71.260388        71.260388   \n",
       "1  Precision  77.039529      80.000000  80.000000  79.811321        79.867675   \n",
       "2     Rappel  87.488061      86.723973  86.723973  80.802292        80.706781   \n",
       "\n",
       "   arbre pca  \n",
       "0  71.814404  \n",
       "1  80.018762  \n",
       "2  81.470869  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['arbre pca'] = arbre_pca\n",
    "df['KNN pca'] = knn_pca\n",
    "df.reindex_axis(sorted(df.columns), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Sélection de variables :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Income' 'Seniority' 'Price' 'Amount' 'Age' 'Assets' 'Expenses' 'Records'\n",
      " 'Time' 'Job' 'Debt' 'Home' 'Marital']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X)\n",
    "X_scaled = scaler.transform(X)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_scaled, Y, test_size=0.33, random_state=42)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from numpy.core.umath_tests import inner1d\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "clf.fit(X_scaled, Y)\n",
    "importances=clf.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in clf.estimators_],axis=0)\n",
    "sorted_idx = np.argsort(importances)[::-1]\n",
    "features = np.asarray(list(data_df))\n",
    "print(features[sorted_idx])\n",
    "padding = np.arange(X_train.size/len(X_train)) + 0.5\n",
    "plt.barh(padding, importances[sorted_idx],xerr=std[sorted_idx], align='center')\n",
    "plt.yticks(padding, features[sorted_idx])\n",
    "plt.xlabel(\"Relative Importance\")\n",
    "plt.title(\"Variable Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "KNN=KNeighborsClassifier(n_neighbors=5)\n",
    "scores=np.zeros(X_train.shape[1]+1)\n",
    "for f in np.arange(0, X_train.shape[1]+1):\n",
    "    X1_f = X_train[:,sorted_idx[:f+1]]\n",
    "    X2_f = X_test[:,sorted_idx[:f+1]]\n",
    "    KNN.fit(X1_f,Y_train)\n",
    "    YKNN=KNN.predict(X2_f)\n",
    "    scores[f]=np.round(accuracy_score(Y_test,YKNN),3)\n",
    "plt.plot(scores)\n",
    "plt.xlabel(\"Nombre de Variables\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Evolution de l'accuracy en fonction des variables\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Paramétrage des classifieurs : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuner les paramètres algorithmes k-plus proches voisins\n",
    "Le principe des méthodes du k-plus proches voisins est de trouver un nombre k prédéfini d’échantillons d’entraînement le plus proche en distance du nouveau point. En général, un plus grand K supprime les effets du bruit, mais rend les limites de la classification moins distinctes. On va tuner cet paramètres K( n_neighbors)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "df1 = data_df.iloc[:,0:13] \n",
    "k = np.arange(30)+1\n",
    "parameters = {'n_neighbors': k}\n",
    "scores = ['precision', 'recall']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for precision\n",
      "Best parameters set found on development set:\n",
      "{'n_neighbors': 18}\n",
      "Grid scores on development set:\n",
      "0.637 (+/-0.033) for {'n_neighbors': 1}\n",
      "0.635 (+/-0.035) for {'n_neighbors': 2}\n",
      "0.670 (+/-0.059) for {'n_neighbors': 3}\n",
      "0.664 (+/-0.054) for {'n_neighbors': 4}\n",
      "0.685 (+/-0.055) for {'n_neighbors': 5}\n",
      "0.686 (+/-0.043) for {'n_neighbors': 6}\n",
      "0.698 (+/-0.052) for {'n_neighbors': 7}\n",
      "0.701 (+/-0.056) for {'n_neighbors': 8}\n",
      "0.710 (+/-0.049) for {'n_neighbors': 9}\n",
      "0.704 (+/-0.045) for {'n_neighbors': 10}\n",
      "0.704 (+/-0.040) for {'n_neighbors': 11}\n",
      "0.705 (+/-0.030) for {'n_neighbors': 12}\n",
      "0.710 (+/-0.033) for {'n_neighbors': 13}\n",
      "0.707 (+/-0.038) for {'n_neighbors': 14}\n",
      "0.710 (+/-0.035) for {'n_neighbors': 15}\n",
      "0.711 (+/-0.030) for {'n_neighbors': 16}\n",
      "0.710 (+/-0.028) for {'n_neighbors': 17}\n",
      "0.715 (+/-0.036) for {'n_neighbors': 18}\n",
      "0.712 (+/-0.029) for {'n_neighbors': 19}\n",
      "0.715 (+/-0.037) for {'n_neighbors': 20}\n",
      "0.711 (+/-0.036) for {'n_neighbors': 21}\n",
      "0.713 (+/-0.029) for {'n_neighbors': 22}\n",
      "0.707 (+/-0.034) for {'n_neighbors': 23}\n",
      "0.713 (+/-0.034) for {'n_neighbors': 24}\n",
      "0.707 (+/-0.032) for {'n_neighbors': 25}\n",
      "0.707 (+/-0.034) for {'n_neighbors': 26}\n",
      "0.706 (+/-0.033) for {'n_neighbors': 27}\n",
      "0.703 (+/-0.027) for {'n_neighbors': 28}\n",
      "0.706 (+/-0.028) for {'n_neighbors': 29}\n",
      "0.705 (+/-0.028) for {'n_neighbors': 30}\n",
      "Detailed classification report:\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.61      0.47      0.53       397\n",
      "        1.0       0.82      0.88      0.85      1047\n",
      "\n",
      "avg / total       0.76      0.77      0.76      1444\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "Best parameters set found on development set:\n",
      "{'n_neighbors': 8}\n",
      "Grid scores on development set:\n",
      "0.631 (+/-0.035) for {'n_neighbors': 1}\n",
      "0.664 (+/-0.042) for {'n_neighbors': 2}\n",
      "0.651 (+/-0.045) for {'n_neighbors': 3}\n",
      "0.677 (+/-0.063) for {'n_neighbors': 4}\n",
      "0.659 (+/-0.053) for {'n_neighbors': 5}\n",
      "0.687 (+/-0.047) for {'n_neighbors': 6}\n",
      "0.665 (+/-0.044) for {'n_neighbors': 7}\n",
      "0.690 (+/-0.055) for {'n_neighbors': 8}\n",
      "0.671 (+/-0.039) for {'n_neighbors': 9}\n",
      "0.688 (+/-0.043) for {'n_neighbors': 10}\n",
      "0.664 (+/-0.033) for {'n_neighbors': 11}\n",
      "0.685 (+/-0.038) for {'n_neighbors': 12}\n",
      "0.670 (+/-0.036) for {'n_neighbors': 13}\n",
      "0.686 (+/-0.051) for {'n_neighbors': 14}\n",
      "0.670 (+/-0.036) for {'n_neighbors': 15}\n",
      "0.685 (+/-0.038) for {'n_neighbors': 16}\n",
      "0.672 (+/-0.037) for {'n_neighbors': 17}\n",
      "0.689 (+/-0.049) for {'n_neighbors': 18}\n",
      "0.677 (+/-0.044) for {'n_neighbors': 19}\n",
      "0.688 (+/-0.043) for {'n_neighbors': 20}\n",
      "0.671 (+/-0.039) for {'n_neighbors': 21}\n",
      "0.683 (+/-0.038) for {'n_neighbors': 22}\n",
      "0.669 (+/-0.038) for {'n_neighbors': 23}\n",
      "0.686 (+/-0.043) for {'n_neighbors': 24}\n",
      "0.669 (+/-0.040) for {'n_neighbors': 25}\n",
      "0.678 (+/-0.038) for {'n_neighbors': 26}\n",
      "0.668 (+/-0.031) for {'n_neighbors': 27}\n",
      "0.675 (+/-0.031) for {'n_neighbors': 28}\n",
      "0.669 (+/-0.039) for {'n_neighbors': 29}\n",
      "0.675 (+/-0.035) for {'n_neighbors': 30}\n",
      "Detailed classification report:\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.58      0.51      0.54       397\n",
      "        1.0       0.82      0.86      0.84      1047\n",
      "\n",
      "avg / total       0.75      0.76      0.76      1444\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    clf = GridSearchCV(KNN, parameters, cv=10, scoring='%s_macro' % score)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print(clf.best_params_)\n",
    "    print(\"Grid scores on development set:\")\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print(\"Detailed classification report:\")\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    y_true, y_pred = Y_test, clf.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuner les paramètres algorithmes Arbre de décision, \n",
    "Arbre de décision répété plusieurs fois à l'aide de sélections aléatoires de caractéristiques et d'échantillons (technique similaire utilisée dans des forêts aléatoires). Le paramètre random_state du fonction Arbre de décision permet de contrôler ces choix aléatoires. On va tuner cet paramètres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import tree\n",
    "DTC = tree.DecisionTreeClassifier(random_state=1)\n",
    "df1 = data_df.iloc[:,0:13] \n",
    "k = np.arange(40)+1\n",
    "parameters_DTC = {'random_state': k}\n",
    "scores = ['precision', 'recall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for precision\n",
      "Best parameters set found on development set:\n",
      "{'random_state': 15}\n",
      "Grid scores on development set:\n",
      "0.662 (+/-0.054) for {'random_state': 1}\n",
      "0.653 (+/-0.062) for {'random_state': 2}\n",
      "0.654 (+/-0.068) for {'random_state': 3}\n",
      "0.657 (+/-0.045) for {'random_state': 4}\n",
      "0.656 (+/-0.047) for {'random_state': 5}\n",
      "0.652 (+/-0.048) for {'random_state': 6}\n",
      "0.660 (+/-0.054) for {'random_state': 7}\n",
      "0.651 (+/-0.053) for {'random_state': 8}\n",
      "0.648 (+/-0.038) for {'random_state': 9}\n",
      "0.655 (+/-0.061) for {'random_state': 10}\n",
      "0.651 (+/-0.044) for {'random_state': 11}\n",
      "0.656 (+/-0.040) for {'random_state': 12}\n",
      "0.651 (+/-0.038) for {'random_state': 13}\n",
      "0.650 (+/-0.045) for {'random_state': 14}\n",
      "0.663 (+/-0.057) for {'random_state': 15}\n",
      "0.651 (+/-0.045) for {'random_state': 16}\n",
      "0.655 (+/-0.058) for {'random_state': 17}\n",
      "0.649 (+/-0.046) for {'random_state': 18}\n",
      "0.651 (+/-0.036) for {'random_state': 19}\n",
      "0.651 (+/-0.061) for {'random_state': 20}\n",
      "0.656 (+/-0.047) for {'random_state': 21}\n",
      "0.654 (+/-0.061) for {'random_state': 22}\n",
      "0.660 (+/-0.068) for {'random_state': 23}\n",
      "0.654 (+/-0.063) for {'random_state': 24}\n",
      "0.655 (+/-0.062) for {'random_state': 25}\n",
      "0.653 (+/-0.048) for {'random_state': 26}\n",
      "0.648 (+/-0.044) for {'random_state': 27}\n",
      "0.660 (+/-0.062) for {'random_state': 28}\n",
      "0.653 (+/-0.042) for {'random_state': 29}\n",
      "0.650 (+/-0.050) for {'random_state': 30}\n",
      "0.648 (+/-0.043) for {'random_state': 31}\n",
      "0.655 (+/-0.060) for {'random_state': 32}\n",
      "0.658 (+/-0.048) for {'random_state': 33}\n",
      "0.652 (+/-0.056) for {'random_state': 34}\n",
      "0.657 (+/-0.062) for {'random_state': 35}\n",
      "0.647 (+/-0.035) for {'random_state': 36}\n",
      "0.650 (+/-0.040) for {'random_state': 37}\n",
      "0.650 (+/-0.054) for {'random_state': 38}\n",
      "0.650 (+/-0.048) for {'random_state': 39}\n",
      "0.653 (+/-0.046) for {'random_state': 40}\n",
      "Detailed classification report:\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.48      0.48      0.48       397\n",
      "        1.0       0.80      0.80      0.80      1047\n",
      "\n",
      "avg / total       0.71      0.71      0.71      1444\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "Best parameters set found on development set:\n",
      "{'random_state': 15}\n",
      "Grid scores on development set:\n",
      "0.659 (+/-0.042) for {'random_state': 1}\n",
      "0.651 (+/-0.059) for {'random_state': 2}\n",
      "0.653 (+/-0.056) for {'random_state': 3}\n",
      "0.656 (+/-0.035) for {'random_state': 4}\n",
      "0.654 (+/-0.040) for {'random_state': 5}\n",
      "0.650 (+/-0.038) for {'random_state': 6}\n",
      "0.658 (+/-0.042) for {'random_state': 7}\n",
      "0.650 (+/-0.046) for {'random_state': 8}\n",
      "0.647 (+/-0.037) for {'random_state': 9}\n",
      "0.653 (+/-0.057) for {'random_state': 10}\n",
      "0.649 (+/-0.035) for {'random_state': 11}\n",
      "0.656 (+/-0.040) for {'random_state': 12}\n",
      "0.650 (+/-0.030) for {'random_state': 13}\n",
      "0.650 (+/-0.038) for {'random_state': 14}\n",
      "0.662 (+/-0.047) for {'random_state': 15}\n",
      "0.650 (+/-0.040) for {'random_state': 16}\n",
      "0.650 (+/-0.052) for {'random_state': 17}\n",
      "0.649 (+/-0.041) for {'random_state': 18}\n",
      "0.651 (+/-0.030) for {'random_state': 19}\n",
      "0.649 (+/-0.054) for {'random_state': 20}\n",
      "0.656 (+/-0.039) for {'random_state': 21}\n",
      "0.654 (+/-0.052) for {'random_state': 22}\n",
      "0.658 (+/-0.055) for {'random_state': 23}\n",
      "0.652 (+/-0.060) for {'random_state': 24}\n",
      "0.655 (+/-0.055) for {'random_state': 25}\n",
      "0.651 (+/-0.041) for {'random_state': 26}\n",
      "0.648 (+/-0.039) for {'random_state': 27}\n",
      "0.658 (+/-0.047) for {'random_state': 28}\n",
      "0.651 (+/-0.031) for {'random_state': 29}\n",
      "0.648 (+/-0.044) for {'random_state': 30}\n",
      "0.646 (+/-0.038) for {'random_state': 31}\n",
      "0.654 (+/-0.049) for {'random_state': 32}\n",
      "0.657 (+/-0.040) for {'random_state': 33}\n",
      "0.650 (+/-0.047) for {'random_state': 34}\n",
      "0.656 (+/-0.056) for {'random_state': 35}\n",
      "0.647 (+/-0.030) for {'random_state': 36}\n",
      "0.648 (+/-0.039) for {'random_state': 37}\n",
      "0.649 (+/-0.043) for {'random_state': 38}\n",
      "0.649 (+/-0.045) for {'random_state': 39}\n",
      "0.652 (+/-0.036) for {'random_state': 40}\n",
      "Detailed classification report:\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.48      0.48      0.48       397\n",
      "        1.0       0.80      0.80      0.80      1047\n",
      "\n",
      "avg / total       0.71      0.71      0.71      1444\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    clf = GridSearchCV(DTC, parameters_DTC, cv=10, scoring='%s_macro' % score)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print(clf.best_params_)\n",
    "    print(\"Grid scores on development set:\")\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print(\"Detailed classification report:\")\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    y_true, y_pred = Y_test, clf.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Création d’un pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On cree une pipeline avec 2 methode Normalisation(Standard et Min max), ACP et 2 methode de classfication KNN et decisiontree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'KNeighborsClassification Accuracy: 0.747'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe_lr = Pipeline([('scl', StandardScaler()),\n",
    "                    ('pca', PCA()),\n",
    "                    ('clf', KNeighborsClassifier(n_neighbors=5))\n",
    "                   ])\n",
    "\n",
    "pipe_lr.fit(X_train, Y_train)\n",
    "'KNeighborsClassification Accuracy: %.3f' % pipe_lr.score(X_test, Y_test) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DecisionTreeClassifier Accuracy: 0.706'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import tree\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe_lr = Pipeline([('scl', StandardScaler()),\n",
    "                    ('pca', PCA()),\n",
    "                    ('clf', tree.DecisionTreeClassifier(random_state=1))\n",
    "                   ])\n",
    "\n",
    "pipe_lr.fit(X_train, Y_train)\n",
    "'DecisionTreeClassifier Accuracy: %.3f' % pipe_lr.score(X_test, Y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'KNeighborsClassification Accuracy: 0.742'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe_lr = Pipeline([('scl', MinMaxScaler()),\n",
    "                    ('pca', PCA()),\n",
    "                    ('clf', KNeighborsClassifier(n_neighbors=5))\n",
    "                   ])\n",
    "\n",
    "pipe_lr.fit(X_train, Y_train)\n",
    "'KNeighborsClassification Accuracy: %.3f' % pipe_lr.score(X_test, Y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DecisionTreeClassifier Accuracy: 0.705'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import tree\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe_lr = Pipeline([('scl', MinMaxScaler()),\n",
    "                    ('pca', PCA()),\n",
    "                    ('clf', tree.DecisionTreeClassifier(random_state=1))\n",
    "                   ])\n",
    "\n",
    "pipe_lr.fit(X_train, Y_train)\n",
    "'DecisionTreeClassifier Accuracy: %.3f' % pipe_lr.score(X_test, Y_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Comparaison de plusieurs algorithmes d’apprentissage :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La documentation indique que scikit-learn utilise une version optimisée de l'algorithme CART. On ne peut pas donc probablement pas utiliser arbre ID3 \n",
    "http://scikit-learn.org/stable/modules/tree.html#tree-algorithms-id3-c4-5-c5-0-and-cart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_df.values\n",
    "#  variables caractéristiques \n",
    "X = data[:,0:13]\n",
    "#  variable à prédire\n",
    "Y = data[:,13]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for RF is: 0.783 +/- 0.016\n",
      "AUC (Aire sous la courbe ROC) : 0.6839404415638781\n",
      "Accuracy for KNN is: 0.715 +/- 0.017\n",
      "AUC (Aire sous la courbe ROC) : 0.5936115902699087\n",
      "Accuracy for NBS is: 0.772 +/- 0.022\n",
      "AUC (Aire sous la courbe ROC) : 0.6787763527314458\n",
      "Accuracy for MLP is: 0.722 +/- 0.021\n",
      "AUC (Aire sous la courbe ROC) : 0.5\n",
      "Accuracy for DT is: 0.727 +/- 0.025\n",
      "AUC (Aire sous la courbe ROC) : 0.6344900507387066\n",
      "Accuracy for Bagging is: 0.779 +/- 0.011\n",
      "AUC (Aire sous la courbe ROC) : 0.6928034759261799\n",
      "Accuracy for Adaboost is: 0.788 +/- 0.016\n",
      "AUC (Aire sous la courbe ROC) : 0.6913659995332713\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "clfs = {\n",
    "'RF': RandomForestClassifier(n_estimators=50),\n",
    "'KNN': KNeighborsClassifier(n_neighbors=5),\n",
    "'NBS':GaussianNB(),\n",
    "'MLP':MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(20, 10), random_state=1), ## MultilayerPerceptron à deux couches de tailles respectives 20 et 10\n",
    "'DT':DecisionTreeClassifier(random_state=1), \n",
    "'Bagging': BaggingClassifier(n_estimators=50),\n",
    "'Adaboost': AdaBoostClassifier(n_estimators=50, random_state=1)\n",
    "}\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "for i in clfs:\n",
    "    clf = clfs[i]\n",
    "    cv_acc = cross_val_score(clf, X, Y, cv=kf)\n",
    "    print(\"Accuracy for {0} is: {1:.3f} +/- {2:.3f}\".format(i, np.mean(cv_acc), np.std(cv_acc)))\n",
    "    clf.fit(X_train, Y_train)\n",
    "    Y_predict = clf.predict(X_test)\n",
    "    print(\"AUC (Aire sous la courbe ROC) :\", roc_auc_score( Y_test, Y_predict))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## l’estimation aussi par 5 fold cross-validation du critère precision qu'on semble le plus pertinent entre le rappel et precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision for RF is: 0.819 +/- 0.007\n",
      "La precision:  81.31487889273356 %\n",
      "Time d'execution: 0.20145416259765625 seconds ---\n",
      "Precision for KNN is: 0.766 +/- 0.009\n",
      "La precision:  77.03952901597981 %\n",
      "Time d'execution: 0.015625476837158203 seconds ---\n",
      "Precision for NBS is: 0.833 +/- 0.013\n",
      "La precision:  81.69642857142857 %\n",
      "Time d'execution: 0.01560831069946289 seconds ---\n",
      "Precision for MLP is: 0.722 +/- 0.009\n",
      "La precision:  72.50692520775624 %\n",
      "Time d'execution: 0.05896592140197754 seconds ---\n",
      "Precision for DT is: 0.804 +/- 0.011\n",
      "La precision:  79.81132075471699 %\n",
      "Time d'execution: 0.015992164611816406 seconds ---\n",
      "Precision for Bagging is: 0.825 +/- 0.006\n",
      "La precision:  82.55813953488372 %\n",
      "Time d'execution: 0.5072317123413086 seconds ---\n",
      "Precision for Adaboost is: 0.823 +/- 0.012\n",
      "La precision:  82.08695652173913 %\n",
      "Time d'execution: 0.15625667572021484 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "for i in clfs:\n",
    "    clf = clfs[i]\n",
    "    cv_acc = cross_val_score(clf, X, Y, cv=kf, scoring=\"precision\")\n",
    "    start_time = time.time()\n",
    "    print(\"Precision for {0} is: {1:.3f} +/- {2:.3f}\".format(i, np.mean(cv_acc), np.std(cv_acc)))\n",
    "    clf.fit(X_train, Y_train)\n",
    "    Y_predict = clf.predict(X_test)\n",
    "    print(\"La precision: \", precision_score(Y_test, Y_predict)*100, \"%\")\n",
    "    print(\"Time d'execution: %s seconds ---\" % (time.time() - start_time))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonction run_classifiers qui permettra de lancer la comparaison des algorithmes de classification supervisée et qui prendra en paramètre un dictionnaire clfs, le tableau de données caractéristiques X et la target Y. (c.f. def)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Bagging is: 0.779 +/- 0.007\n",
      "La precision:  82.41563055062167 %\n",
      "Time d'execution: 0.5185546875 seconds ---\n",
      "Accuracy for Adaboost is: 0.791 +/- 0.009\n",
      "La precision:  82.08695652173913 %\n",
      "Time d'execution: 0.14251136779785156 seconds ---\n"
     ]
    }
   ],
   "source": [
    "def run_classifiers(clfs, X , Y):\n",
    "    import time\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "    for i in clfs:\n",
    "        clf = clfs[i]\n",
    "        cv_acc = cross_val_score(clf, X, Y, cv=kf)\n",
    "        start_time = time.time()\n",
    "        print(\"Accuracy for {0} is: {1:.3f} +/- {2:.3f}\".format(i, np.mean(cv_acc), np.std(cv_acc)))\n",
    "        clf.fit(X_train, Y_train)\n",
    "        Y_predict = clf.predict(X_test)\n",
    "        print(\"La precision: \", precision_score(Y_test, Y_predict)*100, \"%\")\n",
    "        print(\"Time d'execution: %s seconds ---\" % (time.time() - start_time))\n",
    "clfs1 = {\n",
    "'Bagging': BaggingClassifier(n_estimators=50),\n",
    "'Adaboost': AdaBoostClassifier(n_estimators=50, random_state=1)\n",
    "}\n",
    "\n",
    "run_classifiers(clfs1, X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Apprentissage supervisé : Données hétérogènes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Chargement des données et préparation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#creer nom_collone suivre attribute information https://archive.ics.uci.edu/ml/datasets/Credit+Approval\n",
    "nom_collone= []\n",
    "\n",
    "for i in range(1,17):\n",
    "   nom_collone.append(\"A\" + str(i))\n",
    "\n",
    "data_df = pd.read_csv('./credit.data', sep='\\t' , names = nom_collone)\n",
    "#numpy array values\n",
    "data = data_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A3</th>\n",
       "      <th>A8</th>\n",
       "      <th>A11</th>\n",
       "      <th>A15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.460</td>\n",
       "      <td>3.040</td>\n",
       "      <td>6</td>\n",
       "      <td>560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.500</td>\n",
       "      <td>1.500</td>\n",
       "      <td>0</td>\n",
       "      <td>824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.540</td>\n",
       "      <td>3.750</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.625</td>\n",
       "      <td>1.710</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.000</td>\n",
       "      <td>2.500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.040</td>\n",
       "      <td>6.500</td>\n",
       "      <td>0</td>\n",
       "      <td>31285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11.585</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0</td>\n",
       "      <td>1349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.500</td>\n",
       "      <td>3.960</td>\n",
       "      <td>0</td>\n",
       "      <td>314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.915</td>\n",
       "      <td>3.165</td>\n",
       "      <td>0</td>\n",
       "      <td>1442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.830</td>\n",
       "      <td>2.165</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.835</td>\n",
       "      <td>4.335</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6.040</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0</td>\n",
       "      <td>2690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10.500</td>\n",
       "      <td>5.000</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4.415</td>\n",
       "      <td>0.250</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.960</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5.875</td>\n",
       "      <td>3.170</td>\n",
       "      <td>10</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.250</td>\n",
       "      <td>0.665</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>8.585</td>\n",
       "      <td>0.750</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>11.250</td>\n",
       "      <td>2.500</td>\n",
       "      <td>17</td>\n",
       "      <td>1208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.835</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>8.000</td>\n",
       "      <td>7.875</td>\n",
       "      <td>6</td>\n",
       "      <td>1260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>14.500</td>\n",
       "      <td>3.085</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>6.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.585</td>\n",
       "      <td>1.500</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>13.000</td>\n",
       "      <td>5.165</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>18.500</td>\n",
       "      <td>15.000</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>8.500</td>\n",
       "      <td>7.000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.040</td>\n",
       "      <td>5.000</td>\n",
       "      <td>6</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>9.000</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>3.500</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>1.500</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>4.000</td>\n",
       "      <td>1.500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>1.500</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>0.040</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>11.750</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>0.540</td>\n",
       "      <td>1.750</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>0.500</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>2.040</td>\n",
       "      <td>1.500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>5.835</td>\n",
       "      <td>5.500</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>12.835</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>0.835</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>2.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>2.500</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0</td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>1.040</td>\n",
       "      <td>0.665</td>\n",
       "      <td>0</td>\n",
       "      <td>237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>10.665</td>\n",
       "      <td>0.085</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>7.250</td>\n",
       "      <td>0.040</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>10.210</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>1.250</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>0.290</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0</td>\n",
       "      <td>364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>1.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0</td>\n",
       "      <td>537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>3.290</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>0.750</td>\n",
       "      <td>0.585</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>3.290</td>\n",
       "      <td>3.500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>10.085</td>\n",
       "      <td>1.250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>0.750</td>\n",
       "      <td>2.000</td>\n",
       "      <td>2</td>\n",
       "      <td>394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>13.500</td>\n",
       "      <td>2.000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>0.205</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>3.375</td>\n",
       "      <td>8.290</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>688 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         A3      A8  A11    A15\n",
       "0     0.000   1.250    1      0\n",
       "1     4.460   3.040    6    560\n",
       "2     0.500   1.500    0    824\n",
       "3     1.540   3.750    5      3\n",
       "4     5.625   1.710    0      0\n",
       "5     4.000   2.500    0      0\n",
       "6     1.040   6.500    0  31285\n",
       "7    11.585   0.040    0   1349\n",
       "8     0.500   3.960    0    314\n",
       "9     4.915   3.165    0   1442\n",
       "10    0.830   2.165    0      0\n",
       "11    1.835   4.335    0    200\n",
       "12    6.000   1.000    0      0\n",
       "13    6.040   0.040    0   2690\n",
       "14   10.500   5.000    7      0\n",
       "15    4.415   0.250   10      0\n",
       "16    0.875   0.960    3      0\n",
       "17    5.875   3.170   10    245\n",
       "18    0.250   0.665    0      0\n",
       "19    8.585   0.750    7      0\n",
       "20   11.250   2.500   17   1208\n",
       "21    1.000   0.835    0      0\n",
       "22    8.000   7.875    6   1260\n",
       "23   14.500   3.085    1     11\n",
       "24    6.500   0.500    3      0\n",
       "25    0.585   1.500    2      0\n",
       "26   13.000   5.165    9      0\n",
       "27   18.500  15.000   17      0\n",
       "28    8.500   7.000    3      0\n",
       "29    1.040   5.000    6  10000\n",
       "..      ...     ...  ...    ...\n",
       "658   9.000   0.085    0      0\n",
       "659   3.500   0.165    0      0\n",
       "660   1.500   0.875    0      0\n",
       "661   4.000   1.500    0      0\n",
       "662   1.500   0.040    0      0\n",
       "663   0.040   0.040    0      0\n",
       "664  11.750   0.250    0      0\n",
       "665   0.540   1.750    1      5\n",
       "666   0.500   0.085    0      0\n",
       "667   2.040   1.500    0      1\n",
       "668   5.835   5.500    0    150\n",
       "669  12.835   0.500    0      2\n",
       "670   0.835   0.500    0    117\n",
       "671   2.000   2.000    0     17\n",
       "672   2.500   0.210    0    246\n",
       "673   1.040   0.665    0    237\n",
       "674  10.665   0.085   12      3\n",
       "675   7.250   0.040    1      1\n",
       "676  10.210   0.000    0     50\n",
       "677   1.250   0.000    0      0\n",
       "678   0.290   0.290    0    364\n",
       "679   1.000   3.000    0    537\n",
       "680   3.290   0.335    0      2\n",
       "681   0.750   0.585    0      3\n",
       "682   3.290   3.500    0      0\n",
       "683  10.085   1.250    0      0\n",
       "684   0.750   2.000    2    394\n",
       "685  13.500   2.000    1      1\n",
       "686   0.205   0.040    0    750\n",
       "687   3.375   8.290    0      0\n",
       "\n",
       "[688 rows x 4 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df_sous = data_df.select_dtypes([np.number])                                    \n",
    "data_df_sous = data_df_sous.replace('?', np.NaN)\n",
    "data_df_sous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A3</th>\n",
       "      <th>A8</th>\n",
       "      <th>A11</th>\n",
       "      <th>A15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.460</td>\n",
       "      <td>3.040</td>\n",
       "      <td>6</td>\n",
       "      <td>560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.500</td>\n",
       "      <td>1.500</td>\n",
       "      <td>0</td>\n",
       "      <td>824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.540</td>\n",
       "      <td>3.750</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.625</td>\n",
       "      <td>1.710</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.000</td>\n",
       "      <td>2.500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.040</td>\n",
       "      <td>6.500</td>\n",
       "      <td>0</td>\n",
       "      <td>31285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11.585</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0</td>\n",
       "      <td>1349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.500</td>\n",
       "      <td>3.960</td>\n",
       "      <td>0</td>\n",
       "      <td>314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.915</td>\n",
       "      <td>3.165</td>\n",
       "      <td>0</td>\n",
       "      <td>1442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.830</td>\n",
       "      <td>2.165</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.835</td>\n",
       "      <td>4.335</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6.040</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0</td>\n",
       "      <td>2690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10.500</td>\n",
       "      <td>5.000</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4.415</td>\n",
       "      <td>0.250</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.960</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5.875</td>\n",
       "      <td>3.170</td>\n",
       "      <td>10</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.250</td>\n",
       "      <td>0.665</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>8.585</td>\n",
       "      <td>0.750</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>11.250</td>\n",
       "      <td>2.500</td>\n",
       "      <td>17</td>\n",
       "      <td>1208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.835</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>8.000</td>\n",
       "      <td>7.875</td>\n",
       "      <td>6</td>\n",
       "      <td>1260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>14.500</td>\n",
       "      <td>3.085</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>6.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.585</td>\n",
       "      <td>1.500</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>13.000</td>\n",
       "      <td>5.165</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>18.500</td>\n",
       "      <td>15.000</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>8.500</td>\n",
       "      <td>7.000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.040</td>\n",
       "      <td>5.000</td>\n",
       "      <td>6</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>9.000</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>3.500</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>1.500</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>4.000</td>\n",
       "      <td>1.500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>1.500</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>0.040</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>11.750</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>0.540</td>\n",
       "      <td>1.750</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>0.500</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>2.040</td>\n",
       "      <td>1.500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>5.835</td>\n",
       "      <td>5.500</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>12.835</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>0.835</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>2.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>2.500</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0</td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>1.040</td>\n",
       "      <td>0.665</td>\n",
       "      <td>0</td>\n",
       "      <td>237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>10.665</td>\n",
       "      <td>0.085</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>7.250</td>\n",
       "      <td>0.040</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>10.210</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>1.250</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>0.290</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0</td>\n",
       "      <td>364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>1.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0</td>\n",
       "      <td>537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>3.290</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>0.750</td>\n",
       "      <td>0.585</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>3.290</td>\n",
       "      <td>3.500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>10.085</td>\n",
       "      <td>1.250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>0.750</td>\n",
       "      <td>2.000</td>\n",
       "      <td>2</td>\n",
       "      <td>394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>13.500</td>\n",
       "      <td>2.000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>0.205</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>3.375</td>\n",
       "      <td>8.290</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>688 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         A3      A8  A11    A15\n",
       "0     0.000   1.250    1      0\n",
       "1     4.460   3.040    6    560\n",
       "2     0.500   1.500    0    824\n",
       "3     1.540   3.750    5      3\n",
       "4     5.625   1.710    0      0\n",
       "5     4.000   2.500    0      0\n",
       "6     1.040   6.500    0  31285\n",
       "7    11.585   0.040    0   1349\n",
       "8     0.500   3.960    0    314\n",
       "9     4.915   3.165    0   1442\n",
       "10    0.830   2.165    0      0\n",
       "11    1.835   4.335    0    200\n",
       "12    6.000   1.000    0      0\n",
       "13    6.040   0.040    0   2690\n",
       "14   10.500   5.000    7      0\n",
       "15    4.415   0.250   10      0\n",
       "16    0.875   0.960    3      0\n",
       "17    5.875   3.170   10    245\n",
       "18    0.250   0.665    0      0\n",
       "19    8.585   0.750    7      0\n",
       "20   11.250   2.500   17   1208\n",
       "21    1.000   0.835    0      0\n",
       "22    8.000   7.875    6   1260\n",
       "23   14.500   3.085    1     11\n",
       "24    6.500   0.500    3      0\n",
       "25    0.585   1.500    2      0\n",
       "26   13.000   5.165    9      0\n",
       "27   18.500  15.000   17      0\n",
       "28    8.500   7.000    3      0\n",
       "29    1.040   5.000    6  10000\n",
       "..      ...     ...  ...    ...\n",
       "658   9.000   0.085    0      0\n",
       "659   3.500   0.165    0      0\n",
       "660   1.500   0.875    0      0\n",
       "661   4.000   1.500    0      0\n",
       "662   1.500   0.040    0      0\n",
       "663   0.040   0.040    0      0\n",
       "664  11.750   0.250    0      0\n",
       "665   0.540   1.750    1      5\n",
       "666   0.500   0.085    0      0\n",
       "667   2.040   1.500    0      1\n",
       "668   5.835   5.500    0    150\n",
       "669  12.835   0.500    0      2\n",
       "670   0.835   0.500    0    117\n",
       "671   2.000   2.000    0     17\n",
       "672   2.500   0.210    0    246\n",
       "673   1.040   0.665    0    237\n",
       "674  10.665   0.085   12      3\n",
       "675   7.250   0.040    1      1\n",
       "676  10.210   0.000    0     50\n",
       "677   1.250   0.000    0      0\n",
       "678   0.290   0.290    0    364\n",
       "679   1.000   3.000    0    537\n",
       "680   3.290   0.335    0      2\n",
       "681   0.750   0.585    0      3\n",
       "682   3.290   3.500    0      0\n",
       "683  10.085   1.250    0      0\n",
       "684   0.750   2.000    2    394\n",
       "685  13.500   2.000    1      1\n",
       "686   0.205   0.040    0    750\n",
       "687   3.375   8.290    0      0\n",
       "\n",
       "[688 rows x 4 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Supprimer les individus dans vos données contenant des nan sur au moins une variable.\n",
    "data_df_sous = data_df_sous.dropna()\n",
    "data_df_sous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A3     float64\n",
       "A8     float64\n",
       "A11    float64\n",
       "A15    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df_sous = data_df_sous.astype(float)\n",
    "data_df_sous.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(688, 4)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df_sous.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method hist_frame of          A3      A8   A11      A15\n",
       "0     0.000   1.250   1.0      0.0\n",
       "1     4.460   3.040   6.0    560.0\n",
       "2     0.500   1.500   0.0    824.0\n",
       "3     1.540   3.750   5.0      3.0\n",
       "4     5.625   1.710   0.0      0.0\n",
       "5     4.000   2.500   0.0      0.0\n",
       "6     1.040   6.500   0.0  31285.0\n",
       "7    11.585   0.040   0.0   1349.0\n",
       "8     0.500   3.960   0.0    314.0\n",
       "9     4.915   3.165   0.0   1442.0\n",
       "10    0.830   2.165   0.0      0.0\n",
       "11    1.835   4.335   0.0    200.0\n",
       "12    6.000   1.000   0.0      0.0\n",
       "13    6.040   0.040   0.0   2690.0\n",
       "14   10.500   5.000   7.0      0.0\n",
       "15    4.415   0.250  10.0      0.0\n",
       "16    0.875   0.960   3.0      0.0\n",
       "17    5.875   3.170  10.0    245.0\n",
       "18    0.250   0.665   0.0      0.0\n",
       "19    8.585   0.750   7.0      0.0\n",
       "20   11.250   2.500  17.0   1208.0\n",
       "21    1.000   0.835   0.0      0.0\n",
       "22    8.000   7.875   6.0   1260.0\n",
       "23   14.500   3.085   1.0     11.0\n",
       "24    6.500   0.500   3.0      0.0\n",
       "25    0.585   1.500   2.0      0.0\n",
       "26   13.000   5.165   9.0      0.0\n",
       "27   18.500  15.000  17.0      0.0\n",
       "28    8.500   7.000   3.0      0.0\n",
       "29    1.040   5.000   6.0  10000.0\n",
       "..      ...     ...   ...      ...\n",
       "658   9.000   0.085   0.0      0.0\n",
       "659   3.500   0.165   0.0      0.0\n",
       "660   1.500   0.875   0.0      0.0\n",
       "661   4.000   1.500   0.0      0.0\n",
       "662   1.500   0.040   0.0      0.0\n",
       "663   0.040   0.040   0.0      0.0\n",
       "664  11.750   0.250   0.0      0.0\n",
       "665   0.540   1.750   1.0      5.0\n",
       "666   0.500   0.085   0.0      0.0\n",
       "667   2.040   1.500   0.0      1.0\n",
       "668   5.835   5.500   0.0    150.0\n",
       "669  12.835   0.500   0.0      2.0\n",
       "670   0.835   0.500   0.0    117.0\n",
       "671   2.000   2.000   0.0     17.0\n",
       "672   2.500   0.210   0.0    246.0\n",
       "673   1.040   0.665   0.0    237.0\n",
       "674  10.665   0.085  12.0      3.0\n",
       "675   7.250   0.040   1.0      1.0\n",
       "676  10.210   0.000   0.0     50.0\n",
       "677   1.250   0.000   0.0      0.0\n",
       "678   0.290   0.290   0.0    364.0\n",
       "679   1.000   3.000   0.0    537.0\n",
       "680   3.290   0.335   0.0      2.0\n",
       "681   0.750   0.585   0.0      3.0\n",
       "682   3.290   3.500   0.0      0.0\n",
       "683  10.085   1.250   0.0      0.0\n",
       "684   0.750   2.000   2.0    394.0\n",
       "685  13.500   2.000   1.0      1.0\n",
       "686   0.205   0.040   0.0    750.0\n",
       "687   3.375   8.290   0.0      0.0\n",
       "\n",
       "[688 rows x 4 columns]>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df_sous.hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import auc\n",
    "def run_classifiers(clfs, X , Y):\n",
    "    import time\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "    for i in clfs:\n",
    "        clf = clfs[i]\n",
    "        cv_acc = cross_val_score(clf, X, Y, cv=kf)\n",
    "        start_time = time.time()\n",
    "        print(\"Accuracy for {0} is: {1:.3f} +/- {2:.3f}\".format(i, np.mean(cv_acc), np.std(cv_acc)))\n",
    "        clf.fit(X_train, Y_train)\n",
    "        Y_predict = clf.predict(X_test)\n",
    "        print(\"La precision: \", precision_score(Y_test, Y_predict)*100, \"%\")\n",
    "        print(\"L'AUC: \", auc(Y_test, Y_predict)*100, \"%\") #AUC\n",
    "        print(\"Time d'execution: %s seconds ---\" % (time.time() - start_time))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'slice'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-ff1b3c96da36>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_df_sous\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m14\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m#  variable à prédire\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_df_sous\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2686\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2687\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2688\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2689\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2690\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2693\u001b[0m         \u001b[1;31m# get column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2694\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2695\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2696\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2697\u001b[0m         \u001b[1;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   2485\u001b[0m         \u001b[1;34m\"\"\"Return the cached item, item represents a label indexer.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2486\u001b[0m         \u001b[0mcache\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_item_cache\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2487\u001b[1;33m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2488\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2489\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'slice'"
     ]
    }
   ],
   "source": [
    "X = data_df_sous[:,0:14]\n",
    "#  variable à prédire\n",
    "Y = data_df_sous[:,15]\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X)\n",
    "X_MinMax = scaler.transform(X)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "scaler = StandardScaler ()\n",
    "scaler.fit(X)\n",
    "X_Standard = scaler.transform(X)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_Standard, Y, test_size=0.33, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs1 = {\n",
    "'Bagging': BaggingClassifier(n_estimators=50),\n",
    "'Adaboost': AdaBoostClassifier(n_estimators=50, random_state=1)\n",
    "}\n",
    "run_classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Apprentissage supervisé sur des données textuelles : Feature engineering et Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraction de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 :  Ok lar... Joking wif u oni...\n",
      "1 :  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\n",
      "2 :  U dun say so early hor... U c already then say...\n",
      "3 :  Nah I don't think he goes to usf, he lives around here though\n"
     ]
    }
   ],
   "source": [
    "data_sms_df = pd.read_table('./SMSSpamCollection.data', sep='\\t', header = -1 )\n",
    "Xsms = data_sms_df.values[:,1]\n",
    "Ysms = data_sms_df.values[:,0]\n",
    "for i,x in enumerate(Xsms[0:4]):\n",
    "    print(i,': ', x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 :  00\n",
      "1 :  000\n",
      "2 :  000pes\n",
      "3 :  008704050406\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 2), token_pattern=r'\\b\\w+\\b', min_df=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
