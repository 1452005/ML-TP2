{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créer un nouveau notebook Python et taper le code suivant dans une nouvelle cellule :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(threshold=np.nan,suppress=True)\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Chargement des données et préparation : Dans un premier temps nous allons importer le jeu de données et analyser ses caractéristiques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## • Importer ce jeu de données avec la librairie pandas (c.f. read_csv)\n",
    "\n",
    "## • Transformer votre jeu de données issue de pandas qui sera de type Data Frame en numpy Array (c.f. values) et séparer ensuite les variables caractéristiques de la variable à prédire (status) en deux tableaux différents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv('./credit_scoring.csv', sep=';')\n",
    "data = data_df.values\n",
    "#  variables caractéristiques \n",
    "X = data[:,0:13]\n",
    "#  variable à prédire\n",
    "Y = data[:,13]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## • Analyser les propriétés de vos données : taille de l’échantillon (c.f. shape), nombre d’exemples positifs et négatifs (c.f. hist)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4375, 14)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a 4375 observations dans notre l’échantillon et 14 colonnes (c.à.d 13 variables caractéristiques + 1 variable à prédire)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x000001BAF6E1AAC8>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001BAF71620B8>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001BAF718B710>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001BAF71B2DA0>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x000001BAF71E3470>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001BAF71E34A8>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001BAF723D1D0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001BAF7262860>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x000001BAF728BEF0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001BAF72BC5C0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001BAF72E3C50>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001BAF7316320>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x000001BAF733C9B0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001BAF736E080>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001BAF7395710>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000001BAF73BEDA0>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_df.hist(bins = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## • Pour éviter d’avoir un résultat biaisé du classifieur que nous allons construire, séparer les données en deux partie une dite d’apprentissage qui servira à l’apprentissage du classifieur et l’autre dite de test qui servira à son évaluation (c.f. train_test_split)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "on split notre dataset en deux parties ( un tier pour le test, et deux tiers pour training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Apprentissage et évaluation de modèles : Utiliser ensuite sur votre jeu de données les algorithmes d’apprentissage supervisé suivants :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## • Un arbre CART (random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L’accuracy d'un arbre CART: 71.26038781163435 %\n",
      "La precision d'un arbre CART: 79.81132075471699 %\n",
      "Le rappel d'un arbre CART: 80.80229226361033 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier(random_state=1)\n",
    "clf = clf.fit(X_train, Y_train)\n",
    "Y_pred = clf.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"L’accuracy d'un arbre CART:\", accuracy_score(Y_test, Y_pred)*100, \"%\")\n",
    "from sklearn.metrics import precision_score\n",
    "print(\"La precision d'un arbre CART:\", precision_score(Y_test, Y_pred)*100, \"%\")\n",
    "from sklearn.metrics import recall_score\n",
    "print(\"Le rappel d'un arbre CART:\", recall_score(Y_test, Y_pred)*100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## • k-plus-proches-voisins avec k=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L’accuracy d'un arbre CART: 72.02216066481995 %\n",
      "La precision d'un arbre CART: 77.03952901597981 %\n",
      "Le rappel d'un arbre CART: 87.48806112702961 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf = KNeighborsClassifier(n_neighbors=5)\n",
    "clf = clf.fit(X_train, Y_train)\n",
    "Y_pred = clf.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"L’accuracy d'un arbre CART:\", accuracy_score(Y_test, Y_pred)*100, \"%\")\n",
    "from sklearn.metrics import precision_score\n",
    "print(\"La precision d'un arbre CART:\", precision_score(Y_test, Y_pred)*100, \"%\")\n",
    "from sklearn.metrics import recall_score\n",
    "print(\"Le rappel d'un arbre CART:\", recall_score(Y_test, Y_pred)*100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entre la presicion et le rappel, dans cette application de credit scoring, le presicion est le meilleur critère pour comparer les classifications. Car plus la précision est élevée, plus le faux négatif est faible, ce qui signifie que le montant des créances irrécouvrables (pertes financières) est faible pour la banque. En outre, la précision signifie la perte de client potentiel.\n",
    "\n",
    "En basant sur l'accuracy et le rappel des deux algorithmes, on peut voir que la classification d'arbre CART est préférable de détecter les bons clients et que la classification KNN est préférable de réduire le taux de fausses évaluations des mauvais emprunteurs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Normalisation des variables continues :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MinMaxScaler:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X)\n",
    "X_scaled = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_scaled, Y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L’accuracy d'un arbre CART: 71.26038781163435 %\n",
      "La precision d'un arbre CART: 79.86767485822305 %\n",
      "Le rappel d'un arbre CART: 80.70678127984718 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier(random_state=1)\n",
    "clf = clf.fit(X_train, Y_train)\n",
    "Y_pred = clf.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"L’accuracy d'un arbre CART:\", accuracy_score(Y_test, Y_pred)*100, \"%\")\n",
    "from sklearn.metrics import precision_score\n",
    "print(\"La precision d'un arbre CART:\", precision_score(Y_test, Y_pred)*100, \"%\")\n",
    "from sklearn.metrics import recall_score\n",
    "print(\"Le rappel d'un arbre CART:\", recall_score(Y_test, Y_pred)*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L’accuracy d'un arbre CART: 74.65373961218836 %\n",
      "La precision d'un arbre CART: 80.0 %\n",
      "Le rappel d'un arbre CART: 86.72397325692455 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf = KNeighborsClassifier(n_neighbors=5)\n",
    "clf = clf.fit(X_train, Y_train)\n",
    "Y_pred = clf.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"L’accuracy d'un arbre CART:\", accuracy_score(Y_test, Y_pred)*100, \"%\")\n",
    "from sklearn.metrics import precision_score\n",
    "print(\"La precision d'un arbre CART:\", precision_score(Y_test, Y_pred)*100, \"%\")\n",
    "from sklearn.metrics import recall_score\n",
    "print(\"Le rappel d'un arbre CART:\", recall_score(Y_test, Y_pred)*100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# à conclure: chung ta làm table r KL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Création de nouvelles variables caractéristiques par combinaisons linéaires des variables initiales :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA()\n",
    "pca.fit(X_scaled)\n",
    "X_pca = pca.transform(X_scaled)\n",
    "X_pca = np.concatenate((X_scaled, X_pca), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_pca, Y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L’accuracy d'un arbre CART: 71.81440443213296 %\n",
      "La precision d'un arbre CART: 80.01876172607881 %\n",
      "Le rappel d'un arbre CART: 81.47086914995224 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier(random_state=1)\n",
    "clf = clf.fit(X_train, Y_train)\n",
    "Y_pred = clf.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"L’accuracy d'un arbre CART:\", accuracy_score(Y_test, Y_pred)*100, \"%\")\n",
    "from sklearn.metrics import precision_score\n",
    "print(\"La precision d'un arbre CART:\", precision_score(Y_test, Y_pred)*100, \"%\")\n",
    "from sklearn.metrics import recall_score\n",
    "print(\"Le rappel d'un arbre CART:\", recall_score(Y_test, Y_pred)*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L’accuracy d'un arbre CART: 74.65373961218836 %\n",
      "La precision d'un arbre CART: 80.0 %\n",
      "Le rappel d'un arbre CART: 86.72397325692455 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf = KNeighborsClassifier(n_neighbors=5)\n",
    "clf = clf.fit(X_train, Y_train)\n",
    "Y_pred = clf.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"L’accuracy d'un arbre CART:\", accuracy_score(Y_test, Y_pred)*100, \"%\")\n",
    "from sklearn.metrics import precision_score\n",
    "print(\"La precision d'un arbre CART:\", precision_score(Y_test, Y_pred)*100, \"%\")\n",
    "from sklearn.metrics import recall_score\n",
    "print(\"Le rappel d'un arbre CART:\", recall_score(Y_test, Y_pred)*100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Sélection de variables :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Income' 'Seniority' 'Price' 'Amount' 'Age' 'Assets' 'Expenses' 'Records'\n",
      " 'Time' 'Job' 'Debt' 'Home' 'Marital']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X)\n",
    "X_scaled = scaler.transform(X)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_scaled, Y, test_size=0.33, random_state=42)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from numpy.core.umath_tests import inner1d\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "clf.fit(X_scaled, Y)\n",
    "importances=clf.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in clf.estimators_],axis=0)\n",
    "sorted_idx = np.argsort(importances)[::-1]\n",
    "features = np.asarray(list(data_df))\n",
    "print(features[sorted_idx])\n",
    "padding = np.arange(X_train.size/len(X_train)) + 0.5\n",
    "plt.barh(padding, importances[sorted_idx],xerr=std[sorted_idx], align='center')\n",
    "plt.yticks(padding, features[sorted_idx])\n",
    "plt.xlabel(\"Relative Importance\")\n",
    "plt.title(\"Variable Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "KNN=KNeighborsClassifier(n_neighbors=5)\n",
    "scores=np.zeros(X_train.shape[1]+1)\n",
    "for f in np.arange(0, X_train.shape[1]+1):\n",
    "    X1_f = X_train[:,sorted_idx[:f+1]]\n",
    "    X2_f = X_test[:,sorted_idx[:f+1]]\n",
    "    KNN.fit(X1_f,Y_train)\n",
    "    YKNN=KNN.predict(X2_f)\n",
    "    scores[f]=np.round(accuracy_score(Y_test,YKNN),3)\n",
    "plt.plot(scores)\n",
    "plt.xlabel(\"Nombre de Variables\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Evolution de l'accuracy en fonction des variables\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Paramétrage des classifieurs : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuner les paramètres algorithmes k-plus proches voisins\n",
    "Le principe des méthodes du k-plus proches voisins est de trouver un nombre k prédéfini d’échantillons d’entraînement le plus proche en distance du nouveau point. En général, un plus grand K supprime les effets du bruit, mais rend les limites de la classification moins distinctes. On va tuner cet paramètres K( n_neighbors)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "df1 = data_df.iloc[:,0:13] \n",
    "k = np.arange(30)+1\n",
    "parameters = {'n_neighbors': k}\n",
    "scores = ['precision', 'recall']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for precision\n",
      "Best parameters set found on development set:\n",
      "{'n_neighbors': 18}\n",
      "Grid scores on development set:\n",
      "0.637 (+/-0.033) for {'n_neighbors': 1}\n",
      "0.635 (+/-0.035) for {'n_neighbors': 2}\n",
      "0.670 (+/-0.059) for {'n_neighbors': 3}\n",
      "0.664 (+/-0.054) for {'n_neighbors': 4}\n",
      "0.685 (+/-0.055) for {'n_neighbors': 5}\n",
      "0.686 (+/-0.043) for {'n_neighbors': 6}\n",
      "0.698 (+/-0.052) for {'n_neighbors': 7}\n",
      "0.701 (+/-0.056) for {'n_neighbors': 8}\n",
      "0.710 (+/-0.049) for {'n_neighbors': 9}\n",
      "0.704 (+/-0.045) for {'n_neighbors': 10}\n",
      "0.704 (+/-0.040) for {'n_neighbors': 11}\n",
      "0.705 (+/-0.030) for {'n_neighbors': 12}\n",
      "0.710 (+/-0.033) for {'n_neighbors': 13}\n",
      "0.707 (+/-0.038) for {'n_neighbors': 14}\n",
      "0.710 (+/-0.035) for {'n_neighbors': 15}\n",
      "0.711 (+/-0.030) for {'n_neighbors': 16}\n",
      "0.710 (+/-0.028) for {'n_neighbors': 17}\n",
      "0.715 (+/-0.036) for {'n_neighbors': 18}\n",
      "0.712 (+/-0.029) for {'n_neighbors': 19}\n",
      "0.715 (+/-0.037) for {'n_neighbors': 20}\n",
      "0.711 (+/-0.036) for {'n_neighbors': 21}\n",
      "0.713 (+/-0.029) for {'n_neighbors': 22}\n",
      "0.707 (+/-0.034) for {'n_neighbors': 23}\n",
      "0.713 (+/-0.034) for {'n_neighbors': 24}\n",
      "0.707 (+/-0.032) for {'n_neighbors': 25}\n",
      "0.707 (+/-0.034) for {'n_neighbors': 26}\n",
      "0.706 (+/-0.033) for {'n_neighbors': 27}\n",
      "0.703 (+/-0.027) for {'n_neighbors': 28}\n",
      "0.706 (+/-0.028) for {'n_neighbors': 29}\n",
      "0.705 (+/-0.028) for {'n_neighbors': 30}\n",
      "Detailed classification report:\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.61      0.47      0.53       397\n",
      "        1.0       0.82      0.88      0.85      1047\n",
      "\n",
      "avg / total       0.76      0.77      0.76      1444\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "Best parameters set found on development set:\n",
      "{'n_neighbors': 8}\n",
      "Grid scores on development set:\n",
      "0.631 (+/-0.035) for {'n_neighbors': 1}\n",
      "0.664 (+/-0.042) for {'n_neighbors': 2}\n",
      "0.651 (+/-0.045) for {'n_neighbors': 3}\n",
      "0.677 (+/-0.063) for {'n_neighbors': 4}\n",
      "0.659 (+/-0.053) for {'n_neighbors': 5}\n",
      "0.687 (+/-0.047) for {'n_neighbors': 6}\n",
      "0.665 (+/-0.044) for {'n_neighbors': 7}\n",
      "0.690 (+/-0.055) for {'n_neighbors': 8}\n",
      "0.671 (+/-0.039) for {'n_neighbors': 9}\n",
      "0.688 (+/-0.043) for {'n_neighbors': 10}\n",
      "0.664 (+/-0.033) for {'n_neighbors': 11}\n",
      "0.685 (+/-0.038) for {'n_neighbors': 12}\n",
      "0.670 (+/-0.036) for {'n_neighbors': 13}\n",
      "0.686 (+/-0.051) for {'n_neighbors': 14}\n",
      "0.670 (+/-0.036) for {'n_neighbors': 15}\n",
      "0.685 (+/-0.038) for {'n_neighbors': 16}\n",
      "0.672 (+/-0.037) for {'n_neighbors': 17}\n",
      "0.689 (+/-0.049) for {'n_neighbors': 18}\n",
      "0.677 (+/-0.044) for {'n_neighbors': 19}\n",
      "0.688 (+/-0.043) for {'n_neighbors': 20}\n",
      "0.671 (+/-0.039) for {'n_neighbors': 21}\n",
      "0.683 (+/-0.038) for {'n_neighbors': 22}\n",
      "0.669 (+/-0.038) for {'n_neighbors': 23}\n",
      "0.686 (+/-0.043) for {'n_neighbors': 24}\n",
      "0.669 (+/-0.040) for {'n_neighbors': 25}\n",
      "0.678 (+/-0.038) for {'n_neighbors': 26}\n",
      "0.668 (+/-0.031) for {'n_neighbors': 27}\n",
      "0.675 (+/-0.031) for {'n_neighbors': 28}\n",
      "0.669 (+/-0.039) for {'n_neighbors': 29}\n",
      "0.675 (+/-0.035) for {'n_neighbors': 30}\n",
      "Detailed classification report:\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.58      0.51      0.54       397\n",
      "        1.0       0.82      0.86      0.84      1047\n",
      "\n",
      "avg / total       0.75      0.76      0.76      1444\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    clf = GridSearchCV(KNN, parameters, cv=10, scoring='%s_macro' % score)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print(clf.best_params_)\n",
    "    print(\"Grid scores on development set:\")\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print(\"Detailed classification report:\")\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    y_true, y_pred = Y_test, clf.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuner les paramètres algorithmes Arbre de décision, \n",
    "Arbre de décision répété plusieurs fois à l'aide de sélections aléatoires de caractéristiques et d'échantillons (technique similaire utilisée dans des forêts aléatoires). Le paramètre random_state du fonction Arbre de décision permet de contrôler ces choix aléatoires. On va tuner cet paramètres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import tree\n",
    "DTC = tree.DecisionTreeClassifier(random_state=1)\n",
    "df1 = data_df.iloc[:,0:13] \n",
    "k = np.arange(40)+1\n",
    "parameters_DTC = {'random_state': k}\n",
    "scores = ['precision', 'recall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for precision\n",
      "Best parameters set found on development set:\n",
      "{'random_state': 15}\n",
      "Grid scores on development set:\n",
      "0.662 (+/-0.054) for {'random_state': 1}\n",
      "0.653 (+/-0.062) for {'random_state': 2}\n",
      "0.654 (+/-0.068) for {'random_state': 3}\n",
      "0.657 (+/-0.045) for {'random_state': 4}\n",
      "0.656 (+/-0.047) for {'random_state': 5}\n",
      "0.652 (+/-0.048) for {'random_state': 6}\n",
      "0.660 (+/-0.054) for {'random_state': 7}\n",
      "0.651 (+/-0.053) for {'random_state': 8}\n",
      "0.648 (+/-0.038) for {'random_state': 9}\n",
      "0.655 (+/-0.061) for {'random_state': 10}\n",
      "0.651 (+/-0.044) for {'random_state': 11}\n",
      "0.656 (+/-0.040) for {'random_state': 12}\n",
      "0.651 (+/-0.038) for {'random_state': 13}\n",
      "0.650 (+/-0.045) for {'random_state': 14}\n",
      "0.663 (+/-0.057) for {'random_state': 15}\n",
      "0.651 (+/-0.045) for {'random_state': 16}\n",
      "0.655 (+/-0.058) for {'random_state': 17}\n",
      "0.649 (+/-0.046) for {'random_state': 18}\n",
      "0.651 (+/-0.036) for {'random_state': 19}\n",
      "0.651 (+/-0.061) for {'random_state': 20}\n",
      "0.656 (+/-0.047) for {'random_state': 21}\n",
      "0.654 (+/-0.061) for {'random_state': 22}\n",
      "0.660 (+/-0.068) for {'random_state': 23}\n",
      "0.654 (+/-0.063) for {'random_state': 24}\n",
      "0.655 (+/-0.062) for {'random_state': 25}\n",
      "0.653 (+/-0.048) for {'random_state': 26}\n",
      "0.648 (+/-0.044) for {'random_state': 27}\n",
      "0.660 (+/-0.062) for {'random_state': 28}\n",
      "0.653 (+/-0.042) for {'random_state': 29}\n",
      "0.650 (+/-0.050) for {'random_state': 30}\n",
      "0.648 (+/-0.043) for {'random_state': 31}\n",
      "0.655 (+/-0.060) for {'random_state': 32}\n",
      "0.658 (+/-0.048) for {'random_state': 33}\n",
      "0.652 (+/-0.056) for {'random_state': 34}\n",
      "0.657 (+/-0.062) for {'random_state': 35}\n",
      "0.647 (+/-0.035) for {'random_state': 36}\n",
      "0.650 (+/-0.040) for {'random_state': 37}\n",
      "0.650 (+/-0.054) for {'random_state': 38}\n",
      "0.650 (+/-0.048) for {'random_state': 39}\n",
      "0.653 (+/-0.046) for {'random_state': 40}\n",
      "Detailed classification report:\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.48      0.48      0.48       397\n",
      "        1.0       0.80      0.80      0.80      1047\n",
      "\n",
      "avg / total       0.71      0.71      0.71      1444\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "Best parameters set found on development set:\n",
      "{'random_state': 15}\n",
      "Grid scores on development set:\n",
      "0.659 (+/-0.042) for {'random_state': 1}\n",
      "0.651 (+/-0.059) for {'random_state': 2}\n",
      "0.653 (+/-0.056) for {'random_state': 3}\n",
      "0.656 (+/-0.035) for {'random_state': 4}\n",
      "0.654 (+/-0.040) for {'random_state': 5}\n",
      "0.650 (+/-0.038) for {'random_state': 6}\n",
      "0.658 (+/-0.042) for {'random_state': 7}\n",
      "0.650 (+/-0.046) for {'random_state': 8}\n",
      "0.647 (+/-0.037) for {'random_state': 9}\n",
      "0.653 (+/-0.057) for {'random_state': 10}\n",
      "0.649 (+/-0.035) for {'random_state': 11}\n",
      "0.656 (+/-0.040) for {'random_state': 12}\n",
      "0.650 (+/-0.030) for {'random_state': 13}\n",
      "0.650 (+/-0.038) for {'random_state': 14}\n",
      "0.662 (+/-0.047) for {'random_state': 15}\n",
      "0.650 (+/-0.040) for {'random_state': 16}\n",
      "0.650 (+/-0.052) for {'random_state': 17}\n",
      "0.649 (+/-0.041) for {'random_state': 18}\n",
      "0.651 (+/-0.030) for {'random_state': 19}\n",
      "0.649 (+/-0.054) for {'random_state': 20}\n",
      "0.656 (+/-0.039) for {'random_state': 21}\n",
      "0.654 (+/-0.052) for {'random_state': 22}\n",
      "0.658 (+/-0.055) for {'random_state': 23}\n",
      "0.652 (+/-0.060) for {'random_state': 24}\n",
      "0.655 (+/-0.055) for {'random_state': 25}\n",
      "0.651 (+/-0.041) for {'random_state': 26}\n",
      "0.648 (+/-0.039) for {'random_state': 27}\n",
      "0.658 (+/-0.047) for {'random_state': 28}\n",
      "0.651 (+/-0.031) for {'random_state': 29}\n",
      "0.648 (+/-0.044) for {'random_state': 30}\n",
      "0.646 (+/-0.038) for {'random_state': 31}\n",
      "0.654 (+/-0.049) for {'random_state': 32}\n",
      "0.657 (+/-0.040) for {'random_state': 33}\n",
      "0.650 (+/-0.047) for {'random_state': 34}\n",
      "0.656 (+/-0.056) for {'random_state': 35}\n",
      "0.647 (+/-0.030) for {'random_state': 36}\n",
      "0.648 (+/-0.039) for {'random_state': 37}\n",
      "0.649 (+/-0.043) for {'random_state': 38}\n",
      "0.649 (+/-0.045) for {'random_state': 39}\n",
      "0.652 (+/-0.036) for {'random_state': 40}\n",
      "Detailed classification report:\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.48      0.48      0.48       397\n",
      "        1.0       0.80      0.80      0.80      1047\n",
      "\n",
      "avg / total       0.71      0.71      0.71      1444\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    clf = GridSearchCV(DTC, parameters_DTC, cv=10, scoring='%s_macro' % score)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print(clf.best_params_)\n",
    "    print(\"Grid scores on development set:\")\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print(\"Detailed classification report:\")\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    y_true, y_pred = Y_test, clf.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Création d’un pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On cree une pipeline avec 2 methode Normalisation(Standard et Min max), ACP et 2 methode de classfication KNN et decisiontree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'KNeighborsClassification Accuracy: 0.747'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe_lr = Pipeline([('scl', StandardScaler()),\n",
    "                    ('pca', PCA()),\n",
    "                    ('clf', KNeighborsClassifier(n_neighbors=5))\n",
    "                   ])\n",
    "\n",
    "pipe_lr.fit(X_train, Y_train)\n",
    "'KNeighborsClassification Accuracy: %.3f' % pipe_lr.score(X_test, Y_test) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DecisionTreeClassifier Accuracy: 0.706'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import tree\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe_lr = Pipeline([('scl', StandardScaler()),\n",
    "                    ('pca', PCA()),\n",
    "                    ('clf', tree.DecisionTreeClassifier(random_state=1))\n",
    "                   ])\n",
    "\n",
    "pipe_lr.fit(X_train, Y_train)\n",
    "'DecisionTreeClassifier Accuracy: %.3f' % pipe_lr.score(X_test, Y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'KNeighborsClassification Accuracy: 0.742'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe_lr = Pipeline([('scl', MinMaxScaler()),\n",
    "                    ('pca', PCA()),\n",
    "                    ('clf', KNeighborsClassifier(n_neighbors=5))\n",
    "                   ])\n",
    "\n",
    "pipe_lr.fit(X_train, Y_train)\n",
    "'KNeighborsClassification Accuracy: %.3f' % pipe_lr.score(X_test, Y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DecisionTreeClassifier Accuracy: 0.705'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import tree\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe_lr = Pipeline([('scl', MinMaxScaler()),\n",
    "                    ('pca', PCA()),\n",
    "                    ('clf', tree.DecisionTreeClassifier(random_state=1))\n",
    "                   ])\n",
    "\n",
    "pipe_lr.fit(X_train, Y_train)\n",
    "'DecisionTreeClassifier Accuracy: %.3f' % pipe_lr.score(X_test, Y_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Comparaison de plusieurs algorithmes d’apprentissage :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La documentation indique que scikit-learn utilise une version optimisée de l'algorithme CART. On ne peut pas donc probablement pas utiliser arbre ID3 \n",
    "http://scikit-learn.org/stable/modules/tree.html#tree-algorithms-id3-c4-5-c5-0-and-cart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_df.values\n",
    "#  variables caractéristiques \n",
    "X = data[:,0:13]\n",
    "#  variable à prédire\n",
    "Y = data[:,13]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for RF is: 0.778 +/- 0.018\n",
      "AUC (Aire sous la courbe ROC) : 0.6923632111899417\n",
      "Accuracy for KNN is: 0.715 +/- 0.017\n",
      "AUC (Aire sous la courbe ROC) : 0.5936115902699087\n",
      "Accuracy for NBS is: 0.772 +/- 0.022\n",
      "AUC (Aire sous la courbe ROC) : 0.6787763527314458\n",
      "Accuracy for MLP is: 0.722 +/- 0.021\n",
      "AUC (Aire sous la courbe ROC) : 0.5\n",
      "Accuracy for DT is: 0.727 +/- 0.025\n",
      "AUC (Aire sous la courbe ROC) : 0.6344900507387066\n",
      "Accuracy for Bagging is: 0.774 +/- 0.014\n",
      "AUC (Aire sous la courbe ROC) : 0.7005333699017705\n",
      "Accuracy for Adaboost is: 0.788 +/- 0.016\n",
      "AUC (Aire sous la courbe ROC) : 0.6913659995332713\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "clfs = {\n",
    "'RF': RandomForestClassifier(n_estimators=50),\n",
    "'KNN': KNeighborsClassifier(n_neighbors=5),\n",
    "'NBS':GaussianNB(),\n",
    "'MLP':MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(20, 10), random_state=1), ## MultilayerPerceptron à deux couches de tailles respectives 20 et 10\n",
    "'DT':DecisionTreeClassifier(random_state=1), \n",
    "'Bagging': BaggingClassifier(n_estimators=50),\n",
    "'Adaboost': AdaBoostClassifier(n_estimators=50, random_state=1)\n",
    "}\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "for i in clfs:\n",
    "    clf = clfs[i]\n",
    "    cv_acc = cross_val_score(clf, X, Y, cv=kf)\n",
    "    print(\"Accuracy for {0} is: {1:.3f} +/- {2:.3f}\".format(i, np.mean(cv_acc), np.std(cv_acc)))\n",
    "    clf.fit(X_train, Y_train)\n",
    "    Y_predict = clf.predict(X_test)\n",
    "    print(\"AUC (Aire sous la courbe ROC) :\", roc_auc_score( Y_test, Y_predict))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## l’estimation aussi par 5 fold cross-validation du critère precision qu'on semble le plus pertinent entre le rappel et precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision for RF is: 0.820 +/- 0.010\n",
      "La precision:  81.8260120585702 %\n",
      "Time d'execution: 0.2643609046936035 seconds ---\n",
      "Precision for KNN is: 0.766 +/- 0.009\n",
      "La precision:  77.03952901597981 %\n",
      "Time d'execution: 0.041326284408569336 seconds ---\n",
      "Precision for NBS is: 0.833 +/- 0.013\n",
      "La precision:  81.69642857142857 %\n",
      "Time d'execution: 0.0031120777130126953 seconds ---\n",
      "Precision for MLP is: 0.722 +/- 0.009\n",
      "La precision:  72.50692520775624 %\n",
      "Time d'execution: 0.059629201889038086 seconds ---\n",
      "Precision for DT is: 0.804 +/- 0.011\n",
      "La precision:  79.81132075471699 %\n",
      "Time d'execution: 0.025222301483154297 seconds ---\n",
      "Precision for Bagging is: 0.824 +/- 0.006\n",
      "La precision:  82.36347358997314 %\n",
      "Time d'execution: 0.7279934883117676 seconds ---\n",
      "Precision for Adaboost is: 0.823 +/- 0.012\n",
      "La precision:  82.08695652173913 %\n",
      "Time d'execution: 0.2199385166168213 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "for i in clfs:\n",
    "    clf = clfs[i]\n",
    "    cv_acc = cross_val_score(clf, X, Y, cv=kf, scoring=\"precision\")\n",
    "    start_time = time.time()\n",
    "    print(\"Precision for {0} is: {1:.3f} +/- {2:.3f}\".format(i, np.mean(cv_acc), np.std(cv_acc)))\n",
    "    clf.fit(X_train, Y_train)\n",
    "    Y_predict = clf.predict(X_test)\n",
    "    print(\"La precision: \", precision_score(Y_test, Y_predict)*100, \"%\")\n",
    "    print(\"Time d'execution: %s seconds ---\" % (time.time() - start_time))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonction run_classifiers qui permettra de lancer la comparaison des algorithmes de classification supervisée et qui prendra en paramètre un dictionnaire clfs, le tableau de données caractéristiques X et la target Y. (c.f. def)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Bagging is: 0.773 +/- 0.009\n",
      "La precision:  82.4360105913504 %\n",
      "Time d'execution: 0.7556970119476318 seconds ---\n",
      "Accuracy for Adaboost is: 0.791 +/- 0.009\n",
      "La precision:  82.08695652173913 %\n",
      "Time d'execution: 0.2647538185119629 seconds ---\n"
     ]
    }
   ],
   "source": [
    "def run_classifiers(clfs, X , Y):\n",
    "    import time\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "    for i in clfs:\n",
    "        clf = clfs[i]\n",
    "        cv_acc = cross_val_score(clf, X, Y, cv=kf)\n",
    "        start_time = time.time()\n",
    "        print(\"Accuracy for {0} is: {1:.3f} +/- {2:.3f}\".format(i, np.mean(cv_acc), np.std(cv_acc)))\n",
    "        clf.fit(X_train, Y_train)\n",
    "        Y_predict = clf.predict(X_test)\n",
    "        print(\"La precision: \", precision_score(Y_test, Y_predict)*100, \"%\")\n",
    "        print(\"Time d'execution: %s seconds ---\" % (time.time() - start_time))\n",
    "clfs1 = {\n",
    "'Bagging': BaggingClassifier(n_estimators=50),\n",
    "'Adaboost': AdaBoostClassifier(n_estimators=50, random_state=1)\n",
    "}\n",
    "\n",
    "run_classifiers(clfs1, X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Apprentissage supervisé : Données hétérogènes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Chargement des données et préparation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#creer nom_collone suivre attribute information https://archive.ics.uci.edu/ml/datasets/Credit+Approval\n",
    "nom_collone= []\n",
    "\n",
    "for i in range(1,17):\n",
    "   nom_collone.append(\"A\" + str(i))\n",
    "\n",
    "data_df = pd.read_csv('./credit.data', sep='\\t' , names = nom_collone)\n",
    "#numpy array values\n",
    "data = data_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A3</th>\n",
       "      <th>A8</th>\n",
       "      <th>A11</th>\n",
       "      <th>A15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.460</td>\n",
       "      <td>3.040</td>\n",
       "      <td>6</td>\n",
       "      <td>560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.500</td>\n",
       "      <td>1.500</td>\n",
       "      <td>0</td>\n",
       "      <td>824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.540</td>\n",
       "      <td>3.750</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.625</td>\n",
       "      <td>1.710</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.000</td>\n",
       "      <td>2.500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.040</td>\n",
       "      <td>6.500</td>\n",
       "      <td>0</td>\n",
       "      <td>31285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11.585</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0</td>\n",
       "      <td>1349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.500</td>\n",
       "      <td>3.960</td>\n",
       "      <td>0</td>\n",
       "      <td>314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.915</td>\n",
       "      <td>3.165</td>\n",
       "      <td>0</td>\n",
       "      <td>1442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.830</td>\n",
       "      <td>2.165</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.835</td>\n",
       "      <td>4.335</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6.040</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0</td>\n",
       "      <td>2690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10.500</td>\n",
       "      <td>5.000</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4.415</td>\n",
       "      <td>0.250</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.960</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5.875</td>\n",
       "      <td>3.170</td>\n",
       "      <td>10</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.250</td>\n",
       "      <td>0.665</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>8.585</td>\n",
       "      <td>0.750</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>11.250</td>\n",
       "      <td>2.500</td>\n",
       "      <td>17</td>\n",
       "      <td>1208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.835</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>8.000</td>\n",
       "      <td>7.875</td>\n",
       "      <td>6</td>\n",
       "      <td>1260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>14.500</td>\n",
       "      <td>3.085</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>6.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.585</td>\n",
       "      <td>1.500</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>13.000</td>\n",
       "      <td>5.165</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>18.500</td>\n",
       "      <td>15.000</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>8.500</td>\n",
       "      <td>7.000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.040</td>\n",
       "      <td>5.000</td>\n",
       "      <td>6</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>9.000</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>3.500</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>1.500</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>4.000</td>\n",
       "      <td>1.500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>1.500</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>0.040</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>11.750</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>0.540</td>\n",
       "      <td>1.750</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>0.500</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>2.040</td>\n",
       "      <td>1.500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>5.835</td>\n",
       "      <td>5.500</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>12.835</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>0.835</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>2.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>2.500</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0</td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>1.040</td>\n",
       "      <td>0.665</td>\n",
       "      <td>0</td>\n",
       "      <td>237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>10.665</td>\n",
       "      <td>0.085</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>7.250</td>\n",
       "      <td>0.040</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>10.210</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>1.250</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>0.290</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0</td>\n",
       "      <td>364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>1.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0</td>\n",
       "      <td>537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>3.290</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>0.750</td>\n",
       "      <td>0.585</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>3.290</td>\n",
       "      <td>3.500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>10.085</td>\n",
       "      <td>1.250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>0.750</td>\n",
       "      <td>2.000</td>\n",
       "      <td>2</td>\n",
       "      <td>394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>13.500</td>\n",
       "      <td>2.000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>0.205</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>3.375</td>\n",
       "      <td>8.290</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>688 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         A3      A8  A11    A15\n",
       "0     0.000   1.250    1      0\n",
       "1     4.460   3.040    6    560\n",
       "2     0.500   1.500    0    824\n",
       "3     1.540   3.750    5      3\n",
       "4     5.625   1.710    0      0\n",
       "5     4.000   2.500    0      0\n",
       "6     1.040   6.500    0  31285\n",
       "7    11.585   0.040    0   1349\n",
       "8     0.500   3.960    0    314\n",
       "9     4.915   3.165    0   1442\n",
       "10    0.830   2.165    0      0\n",
       "11    1.835   4.335    0    200\n",
       "12    6.000   1.000    0      0\n",
       "13    6.040   0.040    0   2690\n",
       "14   10.500   5.000    7      0\n",
       "15    4.415   0.250   10      0\n",
       "16    0.875   0.960    3      0\n",
       "17    5.875   3.170   10    245\n",
       "18    0.250   0.665    0      0\n",
       "19    8.585   0.750    7      0\n",
       "20   11.250   2.500   17   1208\n",
       "21    1.000   0.835    0      0\n",
       "22    8.000   7.875    6   1260\n",
       "23   14.500   3.085    1     11\n",
       "24    6.500   0.500    3      0\n",
       "25    0.585   1.500    2      0\n",
       "26   13.000   5.165    9      0\n",
       "27   18.500  15.000   17      0\n",
       "28    8.500   7.000    3      0\n",
       "29    1.040   5.000    6  10000\n",
       "..      ...     ...  ...    ...\n",
       "658   9.000   0.085    0      0\n",
       "659   3.500   0.165    0      0\n",
       "660   1.500   0.875    0      0\n",
       "661   4.000   1.500    0      0\n",
       "662   1.500   0.040    0      0\n",
       "663   0.040   0.040    0      0\n",
       "664  11.750   0.250    0      0\n",
       "665   0.540   1.750    1      5\n",
       "666   0.500   0.085    0      0\n",
       "667   2.040   1.500    0      1\n",
       "668   5.835   5.500    0    150\n",
       "669  12.835   0.500    0      2\n",
       "670   0.835   0.500    0    117\n",
       "671   2.000   2.000    0     17\n",
       "672   2.500   0.210    0    246\n",
       "673   1.040   0.665    0    237\n",
       "674  10.665   0.085   12      3\n",
       "675   7.250   0.040    1      1\n",
       "676  10.210   0.000    0     50\n",
       "677   1.250   0.000    0      0\n",
       "678   0.290   0.290    0    364\n",
       "679   1.000   3.000    0    537\n",
       "680   3.290   0.335    0      2\n",
       "681   0.750   0.585    0      3\n",
       "682   3.290   3.500    0      0\n",
       "683  10.085   1.250    0      0\n",
       "684   0.750   2.000    2    394\n",
       "685  13.500   2.000    1      1\n",
       "686   0.205   0.040    0    750\n",
       "687   3.375   8.290    0      0\n",
       "\n",
       "[688 rows x 4 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df_sous = data_df.select_dtypes([np.number])                                    \n",
    "data_df_sous = data_df_sous.replace('?', np.NaN)\n",
    "data_df_sous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A3</th>\n",
       "      <th>A8</th>\n",
       "      <th>A11</th>\n",
       "      <th>A15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.460</td>\n",
       "      <td>3.040</td>\n",
       "      <td>6</td>\n",
       "      <td>560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.500</td>\n",
       "      <td>1.500</td>\n",
       "      <td>0</td>\n",
       "      <td>824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.540</td>\n",
       "      <td>3.750</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.625</td>\n",
       "      <td>1.710</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.000</td>\n",
       "      <td>2.500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.040</td>\n",
       "      <td>6.500</td>\n",
       "      <td>0</td>\n",
       "      <td>31285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11.585</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0</td>\n",
       "      <td>1349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.500</td>\n",
       "      <td>3.960</td>\n",
       "      <td>0</td>\n",
       "      <td>314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.915</td>\n",
       "      <td>3.165</td>\n",
       "      <td>0</td>\n",
       "      <td>1442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.830</td>\n",
       "      <td>2.165</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.835</td>\n",
       "      <td>4.335</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6.040</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0</td>\n",
       "      <td>2690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10.500</td>\n",
       "      <td>5.000</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4.415</td>\n",
       "      <td>0.250</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.960</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5.875</td>\n",
       "      <td>3.170</td>\n",
       "      <td>10</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.250</td>\n",
       "      <td>0.665</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>8.585</td>\n",
       "      <td>0.750</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>11.250</td>\n",
       "      <td>2.500</td>\n",
       "      <td>17</td>\n",
       "      <td>1208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.835</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>8.000</td>\n",
       "      <td>7.875</td>\n",
       "      <td>6</td>\n",
       "      <td>1260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>14.500</td>\n",
       "      <td>3.085</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>6.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.585</td>\n",
       "      <td>1.500</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>13.000</td>\n",
       "      <td>5.165</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>18.500</td>\n",
       "      <td>15.000</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>8.500</td>\n",
       "      <td>7.000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.040</td>\n",
       "      <td>5.000</td>\n",
       "      <td>6</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>9.000</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>3.500</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>1.500</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>4.000</td>\n",
       "      <td>1.500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>1.500</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>0.040</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>11.750</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>0.540</td>\n",
       "      <td>1.750</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>0.500</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>2.040</td>\n",
       "      <td>1.500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>5.835</td>\n",
       "      <td>5.500</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>12.835</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>0.835</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>2.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>2.500</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0</td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>1.040</td>\n",
       "      <td>0.665</td>\n",
       "      <td>0</td>\n",
       "      <td>237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>10.665</td>\n",
       "      <td>0.085</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>7.250</td>\n",
       "      <td>0.040</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>10.210</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>1.250</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>0.290</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0</td>\n",
       "      <td>364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>1.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>0</td>\n",
       "      <td>537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>3.290</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>0.750</td>\n",
       "      <td>0.585</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>3.290</td>\n",
       "      <td>3.500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>10.085</td>\n",
       "      <td>1.250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>0.750</td>\n",
       "      <td>2.000</td>\n",
       "      <td>2</td>\n",
       "      <td>394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>13.500</td>\n",
       "      <td>2.000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>0.205</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>3.375</td>\n",
       "      <td>8.290</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>688 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         A3      A8  A11    A15\n",
       "0     0.000   1.250    1      0\n",
       "1     4.460   3.040    6    560\n",
       "2     0.500   1.500    0    824\n",
       "3     1.540   3.750    5      3\n",
       "4     5.625   1.710    0      0\n",
       "5     4.000   2.500    0      0\n",
       "6     1.040   6.500    0  31285\n",
       "7    11.585   0.040    0   1349\n",
       "8     0.500   3.960    0    314\n",
       "9     4.915   3.165    0   1442\n",
       "10    0.830   2.165    0      0\n",
       "11    1.835   4.335    0    200\n",
       "12    6.000   1.000    0      0\n",
       "13    6.040   0.040    0   2690\n",
       "14   10.500   5.000    7      0\n",
       "15    4.415   0.250   10      0\n",
       "16    0.875   0.960    3      0\n",
       "17    5.875   3.170   10    245\n",
       "18    0.250   0.665    0      0\n",
       "19    8.585   0.750    7      0\n",
       "20   11.250   2.500   17   1208\n",
       "21    1.000   0.835    0      0\n",
       "22    8.000   7.875    6   1260\n",
       "23   14.500   3.085    1     11\n",
       "24    6.500   0.500    3      0\n",
       "25    0.585   1.500    2      0\n",
       "26   13.000   5.165    9      0\n",
       "27   18.500  15.000   17      0\n",
       "28    8.500   7.000    3      0\n",
       "29    1.040   5.000    6  10000\n",
       "..      ...     ...  ...    ...\n",
       "658   9.000   0.085    0      0\n",
       "659   3.500   0.165    0      0\n",
       "660   1.500   0.875    0      0\n",
       "661   4.000   1.500    0      0\n",
       "662   1.500   0.040    0      0\n",
       "663   0.040   0.040    0      0\n",
       "664  11.750   0.250    0      0\n",
       "665   0.540   1.750    1      5\n",
       "666   0.500   0.085    0      0\n",
       "667   2.040   1.500    0      1\n",
       "668   5.835   5.500    0    150\n",
       "669  12.835   0.500    0      2\n",
       "670   0.835   0.500    0    117\n",
       "671   2.000   2.000    0     17\n",
       "672   2.500   0.210    0    246\n",
       "673   1.040   0.665    0    237\n",
       "674  10.665   0.085   12      3\n",
       "675   7.250   0.040    1      1\n",
       "676  10.210   0.000    0     50\n",
       "677   1.250   0.000    0      0\n",
       "678   0.290   0.290    0    364\n",
       "679   1.000   3.000    0    537\n",
       "680   3.290   0.335    0      2\n",
       "681   0.750   0.585    0      3\n",
       "682   3.290   3.500    0      0\n",
       "683  10.085   1.250    0      0\n",
       "684   0.750   2.000    2    394\n",
       "685  13.500   2.000    1      1\n",
       "686   0.205   0.040    0    750\n",
       "687   3.375   8.290    0      0\n",
       "\n",
       "[688 rows x 4 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Supprimer les individus dans vos données contenant des nan sur au moins une variable.\n",
    "data_df_sous = data_df_sous.dropna()\n",
    "data_df_sous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A3     float64\n",
       "A8     float64\n",
       "A11    float64\n",
       "A15    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df_sous = data_df_sous.astype(float)\n",
    "data_df_sous.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(688, 4)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df_sous.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method hist_frame of          A3      A8   A11      A15\n",
       "0     0.000   1.250   1.0      0.0\n",
       "1     4.460   3.040   6.0    560.0\n",
       "2     0.500   1.500   0.0    824.0\n",
       "3     1.540   3.750   5.0      3.0\n",
       "4     5.625   1.710   0.0      0.0\n",
       "5     4.000   2.500   0.0      0.0\n",
       "6     1.040   6.500   0.0  31285.0\n",
       "7    11.585   0.040   0.0   1349.0\n",
       "8     0.500   3.960   0.0    314.0\n",
       "9     4.915   3.165   0.0   1442.0\n",
       "10    0.830   2.165   0.0      0.0\n",
       "11    1.835   4.335   0.0    200.0\n",
       "12    6.000   1.000   0.0      0.0\n",
       "13    6.040   0.040   0.0   2690.0\n",
       "14   10.500   5.000   7.0      0.0\n",
       "15    4.415   0.250  10.0      0.0\n",
       "16    0.875   0.960   3.0      0.0\n",
       "17    5.875   3.170  10.0    245.0\n",
       "18    0.250   0.665   0.0      0.0\n",
       "19    8.585   0.750   7.0      0.0\n",
       "20   11.250   2.500  17.0   1208.0\n",
       "21    1.000   0.835   0.0      0.0\n",
       "22    8.000   7.875   6.0   1260.0\n",
       "23   14.500   3.085   1.0     11.0\n",
       "24    6.500   0.500   3.0      0.0\n",
       "25    0.585   1.500   2.0      0.0\n",
       "26   13.000   5.165   9.0      0.0\n",
       "27   18.500  15.000  17.0      0.0\n",
       "28    8.500   7.000   3.0      0.0\n",
       "29    1.040   5.000   6.0  10000.0\n",
       "..      ...     ...   ...      ...\n",
       "658   9.000   0.085   0.0      0.0\n",
       "659   3.500   0.165   0.0      0.0\n",
       "660   1.500   0.875   0.0      0.0\n",
       "661   4.000   1.500   0.0      0.0\n",
       "662   1.500   0.040   0.0      0.0\n",
       "663   0.040   0.040   0.0      0.0\n",
       "664  11.750   0.250   0.0      0.0\n",
       "665   0.540   1.750   1.0      5.0\n",
       "666   0.500   0.085   0.0      0.0\n",
       "667   2.040   1.500   0.0      1.0\n",
       "668   5.835   5.500   0.0    150.0\n",
       "669  12.835   0.500   0.0      2.0\n",
       "670   0.835   0.500   0.0    117.0\n",
       "671   2.000   2.000   0.0     17.0\n",
       "672   2.500   0.210   0.0    246.0\n",
       "673   1.040   0.665   0.0    237.0\n",
       "674  10.665   0.085  12.0      3.0\n",
       "675   7.250   0.040   1.0      1.0\n",
       "676  10.210   0.000   0.0     50.0\n",
       "677   1.250   0.000   0.0      0.0\n",
       "678   0.290   0.290   0.0    364.0\n",
       "679   1.000   3.000   0.0    537.0\n",
       "680   3.290   0.335   0.0      2.0\n",
       "681   0.750   0.585   0.0      3.0\n",
       "682   3.290   3.500   0.0      0.0\n",
       "683  10.085   1.250   0.0      0.0\n",
       "684   0.750   2.000   2.0    394.0\n",
       "685  13.500   2.000   1.0      1.0\n",
       "686   0.205   0.040   0.0    750.0\n",
       "687   3.375   8.290   0.0      0.0\n",
       "\n",
       "[688 rows x 4 columns]>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df_sous.hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import auc\n",
    "def run_classifiers(clfs, X , Y):\n",
    "    import time\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "    for i in clfs:\n",
    "        clf = clfs[i]\n",
    "        cv_acc = cross_val_score(clf, X, Y, cv=kf)\n",
    "        start_time = time.time()\n",
    "        print(\"Accuracy for {0} is: {1:.3f} +/- {2:.3f}\".format(i, np.mean(cv_acc), np.std(cv_acc)))\n",
    "        clf.fit(X_train, Y_train)\n",
    "        Y_predict = clf.predict(X_test)\n",
    "        print(\"La precision: \", precision_score(Y_test, Y_predict)*100, \"%\")\n",
    "        print(\"L'AUC: \", auc(Y_test, Y_predict)*100, \"%\") #AUC\n",
    "        print(\"Time d'execution: %s seconds ---\" % (time.time() - start_time))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'slice'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-9c22f65da2c4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_df_sous\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m14\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m#  variable à prédire\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_df_sous\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2686\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2687\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2688\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2689\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2690\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2693\u001b[0m         \u001b[1;31m# get column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2694\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2695\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2696\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2697\u001b[0m         \u001b[1;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   2485\u001b[0m         \u001b[1;34m\"\"\"Return the cached item, item represents a label indexer.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2486\u001b[0m         \u001b[0mcache\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_item_cache\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2487\u001b[1;33m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2488\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2489\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'slice'"
     ]
    }
   ],
   "source": [
    "X = data_df_sous[:,0:14]\n",
    "#  variable à prédire\n",
    "Y = data_df_sous[:,15]\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X)\n",
    "X_MinMax = scaler.transform(X)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "scaler = StandardScaler ()\n",
    "scaler.fit(X)\n",
    "X_Standard = scaler.transform(X)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_Standard, Y, test_size=0.33, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs1 = {\n",
    "'Bagging': BaggingClassifier(n_estimators=50),\n",
    "'Adaboost': AdaBoostClassifier(n_estimators=50, random_state=1)\n",
    "}\n",
    "run_classifiers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
